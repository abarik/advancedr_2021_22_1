[{"path":"index.html","id":"introduction","chapter":"1 Introduction","heading":"1 Introduction","text":"Welcome second book R Fundamentals series! second book takes manipulation tabular data create modern graphics R. ’ll primarily using capabilities set packages called tidyverse within book. book aimed beginners R understand basics (check Basic R).","code":""},{"path":"warm-up-exercise.html","id":"warm-up-exercise","chapter":"2 Warm-up exercise","heading":"2 Warm-up exercise","text":"Loftus, S. C. (2021). Basic Statistics R: Reaching Decisions Data. Retrieved https://books.google.hu/books?id=vTASEAAAQBAJ","code":""},{"path":"warm-up-exercise.html","id":"data-structures","chapter":"2 Warm-up exercise","heading":"2.1 Data structures","text":"","code":""},{"path":"warm-up-exercise.html","id":"problems","chapter":"2 Warm-up exercise","heading":"2.1.1 Problems","text":"Consider following set attributes American Film Institute’s top-five movies ever 2007 list.code use create vector named Movie values Citizen Kane, Godfather, Casablanca, Raging Bull, Singing Rain? (Hints: object <- c(), Working character R)code use create vector — giving year movies Problem 1 made — named Year values 1941, 1972, 1942, 1980, 1952?code use create vector — giving run times minutes movies Problem 1 — named RunTime values 119, 177, 102, 129, 103?code use find run times movies hours save vector called RunTimeHours? (Hints: Numeric tranformation)code use create data frame named MovieInfo containing vectors created Problem 1, Problem 2, Problem 3? (Hints: data.frame())","code":""},{"path":"warm-up-exercise.html","id":"manipulation","chapter":"2 Warm-up exercise","heading":"2.2 Manipulation","text":"","code":""},{"path":"warm-up-exercise.html","id":"problems-1","chapter":"2 Warm-up exercise","heading":"2.2.1 Problems","text":"Suppose following data frame named colleges (download ):code use select first, third, tenth, twelfth entries TopSalary vector Colleges data frame? (Hints: Indexing [] operator)code use select elements MedianSalary vector TopSalary greater $400,000? (Hints: d$MedianSalary[d$TopSalary>400000])code use select rows data frame colleges less equal 1000 employees? (Hints: d[condition, ])code use select sample 5 colleges data frame (14 rows)? (Hints: d[sample(x = 1:14, size = 5, replace = F),])Suppose following data frame named Countries (download ):use select rows data frame GDP per capita less 10000 Asia region?code use select sample three nations data frame (10 rows)?code use select nations saw population percent increase greater 1.5%?Suppose following data frame named Olympics (download ):code use select rows data frame host nation also medal leader?code use select rows data frame number competitors per event greater 35?code use select rows data frame number competing nations Winter Olympics least 80?","code":""},{"path":"warm-up-exercise.html","id":"packages","chapter":"2 Warm-up exercise","heading":"2.3 Packages","text":"","code":""},{"path":"warm-up-exercise.html","id":"problems-2","chapter":"2 Warm-up exercise","heading":"2.3.1 Problems","text":"Install Ecdat package. (Hints: install.packages())Say previously installed Ecdat library R wanted call library access datasets . code use call library? (Hints: library())Say wanted call dataset Diamond Ecdat library. code use load dataset R? (Hints: data())","code":""},{"path":"warm-up-exercise.html","id":"frequency-and-numerical-exploratory-analyses","chapter":"2 Warm-up exercise","heading":"2.4 Frequency and numerical exploratory analyses","text":"","code":""},{"path":"warm-up-exercise.html","id":"problems-3","chapter":"2 Warm-up exercise","heading":"2.4.1 Problems","text":"Load leuk dataset MASS library. dataset survival times (time), white blood cell count (wbc), presence morphologic characteristic white blood cells (ag).Generate frequency table presence morphologic characteristic.Find median mean survival time.Find range, IQR, variance, standard deviation white blood cell count.Find correlation white blood cell count survival time.Load survey dataset MASS library. dataset contains survey responses class college students.Create contingency table whether student smoked (Smoke) student’s exercise regimen (Exer). (Hints: table(), DescTools::Desc())Find mean median student’s heart rate (Pulse). (Hints: summary(), DescTools::Desc(), psych::describe())Find range, IQR, variance, standard deviation student age (Age).Find correlation span student’s writing hand (Wr.Hnd) nonwriting hand (NW.Hnd). (Hints: cor(), DescTools::Desc())Load Housing dataset Ecdat library. dataset looks variables affect sales price houses.Create contingency table whether house recreation room (recroom) whether house full basement (fullbase).Find mean median house’s lot size (lotsize).Find range, IQR, variance, standard deviation sales price (price).Find correlation sales price house (price) number bedrooms (bedrooms).","code":""},{"path":"warm-up-exercise.html","id":"graphical-exploratory-analyses","chapter":"2 Warm-up exercise","heading":"2.5 Graphical exploratory analyses","text":"Load Star dataset Ecdat library. dataset looks affect class sizes student learning.Generate scatterplot student’s math score tmathssk reading score treadssk. (Hints: plot(), ggplot() + geom_point())Generate histogram years teaching experience totexpk. (Hints: hist(), ggplot() + geom_histogram())Create new variable Star dataset called totalscore sum student’s math score tmathssk reading score treadssk. (Hints: tranformation)Generate boxplot student’s total score totalscore split class size type classk. (Hints: boxplot(), ggplot() + geom_boxplot())Load survey dataset MASS library. dataset contains survey responses class college students.Generate scatterplot student’s height Height writing hand span Wr.Hnd.Generate histogram student age Age.Generate boxplot student’s heart rate Pulse split student’s exercise regimen Exer.","code":""},{"path":"rmarkdown.html","id":"rmarkdown","chapter":"3 RMarkdown","heading":"3 RMarkdown","text":"RMarkdown framework RStudio easily combining code, data, text interactive charts reports slide decks. RMarkdown based Markdown.","code":""},{"path":"rmarkdown.html","id":"markdown","chapter":"3 RMarkdown","heading":"3.1 Markdown","text":"Markdown markup language. extremely simple markup language, popular Web application. Markdown used format text GitHub, Reddit, Stack Exchange, Trello, RMarkdown.\nMarkap laguages allow authors annotate content. content anything reports websites. HTML widely used markup language.Markdown created John Gruber Aaron Swartz 2004. Markup designed human reader easily parse content.can download example Markdown file illustrate markdown syntax:HeadingsParagraphsLine BreaksEmphasis (Bold, Italic)BlockquotesLists (Ordered, Unordered)CodeHorizontal RulesLinksImagesTablesFootnotesDefinition ListsIt’s important note Markdown comes many different flavors (versions). several lightweight markup languages supersets Markdown. include Gruber’s basic syntax build upon adding additional elements.Many popular Markdown applications use one following lightweight markup languages:CommonMarkCommonMarkGitHub Flavored Markdown (GFM)GitHub Flavored Markdown (GFM)Markdown ExtraMarkdown ExtraMultiMarkdownMultiMarkdownR Markdown - PandocR Markdown - PandocIf familiar Markdown yet, prefer writing Markdown code, RStudio v1.4 included experimental visual editor Markdown documents, feels similar traditional WYSIWYG editors like Word. can find full documentation RStudio Visual R Markdown. visual editor, can visually edit almost Markdown elements supported Pandoc, section headers, figures, tables, footnotes, .Additional resources Markdown:Markdown Cheat Sheet\nquick reference Markdown syntax.Basic Syntax\nMarkdown elements outlined John Gruber’s design document.Extended Syntax\nAdvanced features build basic Markdown syntax.","code":""},{"path":"rmarkdown.html","id":"rmarkdown-1","chapter":"3 RMarkdown","heading":"3.2 RMarkdown","text":"R Markdown understands Pandoc’s Markdown, version Markdown features. Pandoc guide provides extensive resource formatting options.Rmarkdown files plain text files contain information necessary RStudio generate output files, using rmarkdown knitr package. three distinct parts document, fact, written different language.file header tells rmarkdown package type file create. case, HTML document. ’s worth noting header written YAML.text document written Pandoc flavored Markdown.R code want include evaluate document contained within code chunks. delimited pairs three back ticks. Note back ticks actually part Pandoc Markdown syntax. beauty RMarkdown. allows us combine text, images, code, output together huge variety different output formats create rich reports presentations.use RMarkdown need R package available CRAN, called rmarkdown need install use. install way install R package, function install.packages(). rmarkdown package developed folks RStudio. Therefore, RStudio application designed document editor RMarkdown. R Markdown files extension .Rmd. ’s impossible use R Markdown without RStudio, RStudio makes real delight use. rmarkdown package collection many different tools work together convert RMarkdown files, HTML, PDF, Microsoft Word documents, many file types.therefore two components R Markdown: .Rmd file, contains content, rmarkdown package passes .Rmd file generates specify output files.basic workflow structure RMarkdown document shown Figure 3.1, highlighting steps (arrows) intermediate files created producing output. whole process implemented via function rmarkdown::render(). stage explained detail .\nFigure 3.1: diagram illustrating R Markdown document converted final output document.\n","code":""},{"path":"rmarkdown.html","id":"code-chunks","chapter":"3 RMarkdown","heading":"3.3 Code Chunks","text":"run blocks code RMarkdown, use code chunks. Insert new code chunk :Command + Option + Mac, Ctrl + Alt + Linux Windows.Another option “Insert” drop-Icon toolbar selecting R.recommend learning shortcut save time! ’ll insert new code chunk R Markdown Guide moment.","code":""},{"path":"rmarkdown.html","id":"running-code","chapter":"3 RMarkdown","heading":"3.3.1 Running Code","text":"RStudio provides many options running code chunks “Run” drop-tab toolbar.running code chunks often good idea restart R session start clean environment. Command + Shift + F10 Mac Control + Shift + F10 Linux Windows.save time, ’s worth learning shortcuts run code:Run chunks current chunk Command + Option + P Mac, Ctrl + Alt + P Linux Windows.Run current chunk Command + Option + C Command + Shift + Enter Mac. Linux Windows, use Ctrl + Alt + C Ctrl + Shift + Enter run current chunk.Run next chunk Command + Option + N Mac, Ctrl + Alt + N Linux Windows.Run chunks Command + Option + R Command + + Enter Mac. Linux Windows, use Ctrl + Alt + R Ctrl + + Enter run chunks.","code":""},{"path":"rmarkdown.html","id":"control-behavior-with-code-chunk-options","chapter":"3 RMarkdown","heading":"3.3.2 Control Behavior with Code Chunk Options","text":"One great things R Markdown many options control chunk code evaluated presented. allows build presentations reports ground — including code, plots, tables, images — presenting essential information intended audience. example, can include plot results without showing code used generate .Mastering code chunk options essential becoming proficient RMarkdown user. best way learn chunk options try need reports, don’t worry memorizing now. key chunk options learn:echo = FALSE: show code output, run code produce outputs, plots, warnings messages. code chunk generate plot image example .eval = FALSE: Show code, evaluate .fig.show = \"hide\": Hide plots.include = FALSE: Run code, suppress output. helpful setup code. can see example top code chunk image .message = FALSE: Prevent packages printing messages load. also suppress messages generated functions.\nresults = \"hide\": Hides printed output.\nwarning = FALSE: Prevents packages functions displaying warnings.","code":""},{"path":"rmarkdown.html","id":"navigating-sections-and-code-chunks","chapter":"3 RMarkdown","heading":"3.3.3 Navigating Sections and Code Chunks","text":"Naming code chunks useful long documents many chunks. R code chunks, name chunk like : {r my_boring_chunk_name}.named code chunks, can navigate chunks navigator included bottom R Markdown window pane. can also make plots easy identify name can used sections document. navigator also useful quickly jumping another section document.","code":""},{"path":"rmarkdown.html","id":"table-formatting","chapter":"3 RMarkdown","heading":"3.3.4 Table Formatting","text":"Tables R Markdown displayed see R console default. improve aesthetics table RMarkdown document, use function knitr::kable(). ’s example:Table 3.1: First Rows Cars DatasetThere many packages creating tables R Markdown.","code":"\nknitr::kable(head(cars), caption = \"The First Few Rows of the Cars Dataset\")"},{"path":"rmarkdown.html","id":"inline-code","chapter":"3 RMarkdown","heading":"3.4 Inline Code","text":"Directly embed R code R Markdown document inline code. useful want include information data written summary. ’ll add examples inline code R Markdown Guide illustrate works.Use inline code r add code evaluate within backticks. example, ’s can summarize number rows number columns cars dataset ’s built-R:example highlights ’s possible reduce errors reports summarizing information programmatically. alter dataset change number rows columns, need rerun code accurate result. much better trying remember document need update results, determining new numbers, manually changing results. RMarkdown powerful can save time improve quality accuracy reports.","code":"\n## Inline Code\n\nThe `cars` dataset contains 50 rows and 2 columns."},{"path":"rmarkdown.html","id":"output-format-options","chapter":"3 RMarkdown","heading":"3.5 Output Format Options","text":"Now solid understanding format RMarkdown document, let’s discuss format options. Format options apply entire document specified YAML header. R Markdown supports many types output formats.metadata specified YAML header controls output. single RMarkdown document can support many output formats. two types output formats rmarkdown package: documents, presentations. available formats listed :beamer_presentationbeamer_presentationcontext_documentcontext_documentgithub_documentgithub_documenthtml_documenthtml_documentioslides_presentationioslides_presentationlatex_documentlatex_documentmd_documentmd_documentodt_documentodt_documentpdf_documentpdf_documentpowerpoint_presentationpowerpoint_presentationrtf_documentrtf_documentslidy_presentationslidy_presentationword_documentword_documentMore details https://bookdown.org/yihui/rmarkdown/documents.html#documents https://bookdown.org/yihui/rmarkdown/presentations.html#presentations. output formats provided extension packages. output format names YAML metadata Rmd file, need include package name format extension package, e.g.,format rmarkdown package, need rmarkdown:: prefix (although hurt).packages provide even output formats:bookdown package, https://github.com/rstudio/bookdown, makes easy write books, like one. learn , read Authoring Books R Markdown, Yihui Xie, , course, written bookdown. Visit <http://www.bookdown.org> see bookdown books written wider R community.bookdown package, https://github.com/rstudio/bookdown, makes easy write books, like one. learn , read Authoring Books R Markdown, Yihui Xie, , course, written bookdown. Visit <http://www.bookdown.org> see bookdown books written wider R community.prettydoc package, https://github.com/yixuan/prettydoc/, provides lightweight document formats range attractive themes.prettydoc package, https://github.com/yixuan/prettydoc/, provides lightweight document formats range attractive themes.rticles package, https://github.com/rstudio/rticles, compiles selection formats tailored specific scientific journals.rticles package, https://github.com/rstudio/rticles, compiles selection formats tailored specific scientific journals.See http://rmarkdown.rstudio.com/formats.html list even formats. Also see R Markdown Theme Gallery.","code":"output: tufte::tufte_html"},{"path":"rmarkdown.html","id":"further-topics-and-links","chapter":"3 RMarkdown","heading":"3.6 Further topics and links","text":"Word documentshttps://bookdown.org/yihui/rmarkdown-cookbook/word.htmlhttps://rmarkdown.rstudio.com/articles_docx.htmlBibliographyhttps://bookdown.org/yihui/rmarkdown-cookbook/bibliography.htmlCitation Style Language - Style RepositoryCross-referencing within documentshttps://bookdown.org/yihui/rmarkdown-cookbook/cross-ref.htmlCreate diagramshttps://bookdown.org/yihui/rmarkdown-cookbook/diagrams.html","code":""},{"path":"rmarkdown.html","id":"additional-resources","chapter":"3 RMarkdown","heading":"3.7 Additional Resources","text":"R Markdown Cookbook\ncomprehensive free online book contains almost everything need know RMarkdown.RMarkdown ScientistsRStudio Articles RMarkdown\nRStudio published -depth articles using RMarkdown.R Data Science\nHadley Wickham provides great overview authoring RMarkdown.R Markdown: Definitive Guide\ncontains large number technical details, may serve better reference book textbook.Online lesson RStudioR Markdown Cheatsheet. RStudio published numerous cheatsheets working R, including detailed cheatsheet using R Markdown! R Markdown cheatsheet can accessed within RStudio selecting Help > Cheatsheets > R Markdown Cheat Sheet.","code":""},{"path":"advanced-data-manipulation.html","id":"advanced-data-manipulation","chapter":"4 Advanced data manipulation","heading":"4 Advanced data manipulation","text":"chapter focuses exclusively advanced data manipulation. therefore assume basic level comfort data manipulation.","code":""},{"path":"advanced-data-manipulation.html","id":"importing-data","chapter":"4 Advanced data manipulation","heading":"4.1 Importing data","text":"data used analysis found outside world needs imported R. Data comes different formats.Delimited text files common way transferring data systems general. files store tabular data using special characters (known delimiters) indicate rows columns. delimiters include commas, tabs, space, semicolons (;), pipes (|), etc. function read.table() used read delimited text files. accepts argument, file path file returns output data frame.Delimited text files common way transferring data systems general. files store tabular data using special characters (known delimiters) indicate rows columns. delimiters include commas, tabs, space, semicolons (;), pipes (|), etc. function read.table() used read delimited text files. accepts argument, file path file returns output data frame.Binary files complex plain text files accessing information binary files requires use special software. examples binary files frequently see include Microsoft Excel spreadsheets, SAS data sets, Stata data sets, SPSS data set. foreign package contains functions may used import SAS data sets Stata data sets, installed default install R computer. can use readxl package import Microsoft Excel files, haven package import SAS Stata data sets. aren’t going use packages chapter. Instead, ’re going use best rio package import data examples .Binary files complex plain text files accessing information binary files requires use special software. examples binary files frequently see include Microsoft Excel spreadsheets, SAS data sets, Stata data sets, SPSS data set. foreign package contains functions may used import SAS data sets Stata data sets, installed default install R computer. can use readxl package import Microsoft Excel files, haven package import SAS Stata data sets. aren’t going use packages chapter. Instead, ’re going use best rio package import data examples .","code":"\n# Description of gapminder:\n# help(gapminder, package = \"gapminder\")\n\n# importing the gapminder dataset - Delimited text files - ANSI (CP1250)\ngapminder_cp1250 <- read.table(file = \"data/gapminder_ext_CP1250.txt\", header = T, sep = \"\\t\", dec = \",\", fileEncoding = \"latin2\")\n\n# importing the gapminder dataset - Delimited text files - UTF-8\ngapminder_utf8 <- read.table(file = \"data/gapminder_ext_UTF-8.txt\", header = T, sep = \"\\t\", dec = \",\", fileEncoding = \"UTF-8\")\n\n# importing the gapminder dataset - Binary files\nlibrary(rio)\ngapminder_xlsx <- import(file = \"data/gapminder_ext.xlsx\")\n\n# checking class\nclass(gapminder_xlsx)\n#> [1] \"data.frame\""},{"path":"advanced-data-manipulation.html","id":"import-files-directly-from-the-web","chapter":"4 Advanced data manipulation","heading":"4.1.1 Import files directly from the web","text":"functions read.table() rio::import() accept URL place dataset downloads dataset directly.","code":"\n# NCHS - Death rates and life expectancy at birth: \n# https://data.cdc.gov/NCHS/NCHS-Death-rates-and-life-expectancy-at-birth/w9j2-ggv5\n\n# storing URL\ndata_url <- 'https://data.cdc.gov/api/views/w9j2-ggv5/rows.csv?accessType=DOWNLOAD'\n\n# reading in data from the URL - Delimited text file\nlife_expectancy <- read.table(data_url, header = T, sep = \",\", dec = \".\")\n\nhead(life_expectancy, 3)\n#>   Year      Race        Sex Average.Life.Expectancy..Years.\n#> 1 1900 All Races Both Sexes                            47.3\n#> 2 1901 All Races Both Sexes                            49.1\n#> 3 1902 All Races Both Sexes                            51.5\n#>   Age.adjusted.Death.Rate\n#> 1                  2518.0\n#> 2                  2473.1\n#> 3                  2301.3\nnrow(life_expectancy)\n#> [1] 1071\n\n\n# Description of Potthoff-Roy data: \n# help(potthoffroy, package = \"mice\")\n\n# storing URL\ndata_url <- \"https://raw.github.com/abarik/rdata/master/r_alapok/pothoff2.xlsx\"\nlibrary(rio)\npothoff <- import(file = data_url)\nstr(pothoff)\n#> 'data.frame':    108 obs. of  5 variables:\n#>  $ person: num  1 1 1 1 2 2 2 2 3 3 ...\n#>  $ sex   : chr  \"F\" \"F\" \"F\" \"F\" ...\n#>  $ age   : num  8 10 12 14 8 10 12 14 8 10 ...\n#>  $ y     : num  21 20 21.5 23 21 21.5 24 25.5 20.5 24 ...\n#>  $ agefac: num  8 10 12 14 8 10 12 14 8 10 ..."},{"path":"advanced-data-manipulation.html","id":"exporting-data","chapter":"4 Advanced data manipulation","heading":"4.2 Exporting data","text":"function write.table() used export data delimited text file. function rio::export() used export data worksheets Excel file (binary file). type binary file depend extension given file name.","code":"\n# exporting the gapminder dataset - Delimited text files - ANSI (CP1250)\nwrite.table(x = gapminder_xlsx, file = \"output/data/gapminder_CP1250.csv\", quote = F, sep = \";\", dec = \",\", row.names = F, fileEncoding = \"latin2\")\n\n# exporting the gapminder dataset - Delimited text files - UTF-8\nwrite.table(x = gapminder_xlsx, file = \"output/data/gapminder_UTF-8.csv\", quote = F, sep = \";\", dec = \",\", row.names = F, fileEncoding = \"UTF-8\")\n\n# exporting the gapminder dataset - Binary files\nlibrary(rio)\nexport(x = gapminder_xlsx, file = \"output/data/gapminder.xlsx\", overwrite = T)\nexport(x = gapminder_xlsx, file = \"output/data/gapminder.sav\")"},{"path":"advanced-data-manipulation.html","id":"inspecting-a-data-frame","chapter":"4 Advanced data manipulation","heading":"4.3 Inspecting a data frame","text":"use following functions inspect data frame:dim() returns dimensionsnrow() returns number rowsncol() returns number columnsstr() returns column names data types plus first valueshead() returns first six rows default can changed using argument ntail() returns last six rows default can changed using argument n","code":"\ndim(gapminder_xlsx)\n#> [1] 1704    8\nnrow(gapminder_xlsx)\n#> [1] 1704\nncol(gapminder_xlsx)\n#> [1] 8\nstr(gapminder_xlsx)\n#> 'data.frame':    1704 obs. of  8 variables:\n#>  $ country      : chr  \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ...\n#>  $ continent    : chr  \"Asia\" \"Asia\" \"Asia\" \"Asia\" ...\n#>  $ year         : num  1952 1957 1962 1967 1972 ...\n#>  $ lifeExp      : num  28.8 30.3 32 34 36.1 ...\n#>  $ pop          : num  8425333 9240934 10267083 11537966 13079460 ...\n#>  $ gdpPercap    : num  779 821 853 836 740 ...\n#>  $ country_hun  : chr  \"Afganisztán\" \"Afganisztán\" \"Afganisztán\" \"Afganisztán\" ...\n#>  $ continent_hun: chr  \"Ázsia\" \"Ázsia\" \"Ázsia\" \"Ázsia\" ...\nhead(gapminder_xlsx)\n#>       country continent year lifeExp      pop gdpPercap\n#> 1 Afghanistan      Asia 1952  28.801  8425333  779.4453\n#> 2 Afghanistan      Asia 1957  30.332  9240934  820.8530\n#> 3 Afghanistan      Asia 1962  31.997 10267083  853.1007\n#> 4 Afghanistan      Asia 1967  34.020 11537966  836.1971\n#> 5 Afghanistan      Asia 1972  36.088 13079460  739.9811\n#> 6 Afghanistan      Asia 1977  38.438 14880372  786.1134\n#>   country_hun continent_hun\n#> 1 Afganisztán         Ázsia\n#> 2 Afganisztán         Ázsia\n#> 3 Afganisztán         Ázsia\n#> 4 Afganisztán         Ázsia\n#> 5 Afganisztán         Ázsia\n#> 6 Afganisztán         Ázsia\ntail(gapminder_xlsx, n = 4)\n#>       country continent year lifeExp      pop gdpPercap\n#> 1701 Zimbabwe    Africa 1992  60.377 10704340  693.4208\n#> 1702 Zimbabwe    Africa 1997  46.809 11404948  792.4500\n#> 1703 Zimbabwe    Africa 2002  39.989 11926563  672.0386\n#> 1704 Zimbabwe    Africa 2007  43.487 12311143  469.7093\n#>      country_hun continent_hun\n#> 1701    Zimbabwe        Afrika\n#> 1702    Zimbabwe        Afrika\n#> 1703    Zimbabwe        Afrika\n#> 1704    Zimbabwe        Afrika"},{"path":"advanced-data-manipulation.html","id":"manipulating-columns","chapter":"4 Advanced data manipulation","heading":"4.4 Manipulating Columns","text":"","code":""},{"path":"advanced-data-manipulation.html","id":"changing-column-type","chapter":"4 Advanced data manipulation","heading":"4.4.1 Changing column type","text":"importing data, column types can changed assigning new data types .","code":"\nstr(gapminder_xlsx)\n#> 'data.frame':    1704 obs. of  8 variables:\n#>  $ country      : chr  \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ...\n#>  $ continent    : chr  \"Asia\" \"Asia\" \"Asia\" \"Asia\" ...\n#>  $ year         : num  1952 1957 1962 1967 1972 ...\n#>  $ lifeExp      : num  28.8 30.3 32 34 36.1 ...\n#>  $ pop          : num  8425333 9240934 10267083 11537966 13079460 ...\n#>  $ gdpPercap    : num  779 821 853 836 740 ...\n#>  $ country_hun  : chr  \"Afganisztán\" \"Afganisztán\" \"Afganisztán\" \"Afganisztán\" ...\n#>  $ continent_hun: chr  \"Ázsia\" \"Ázsia\" \"Ázsia\" \"Ázsia\" ...\n\n# changing column type\ngapminder_xlsx$country <- factor(gapminder_xlsx$country)\ngapminder_xlsx$continent <- factor(gapminder_xlsx$continent)\ngapminder_xlsx$country_hun <- factor(gapminder_xlsx$country_hun)\ngapminder_xlsx$continent_hun <- factor(gapminder_xlsx$continent_hun)\n\nstr(gapminder_xlsx)\n#> 'data.frame':    1704 obs. of  8 variables:\n#>  $ country      : Factor w/ 142 levels \"Afghanistan\",..: 1 1 1 1 1 1 1 1 1 1 ...\n#>  $ continent    : Factor w/ 5 levels \"Africa\",\"Americas\",..: 3 3 3 3 3 3 3 3 3 3 ...\n#>  $ year         : num  1952 1957 1962 1967 1972 ...\n#>  $ lifeExp      : num  28.8 30.3 32 34 36.1 ...\n#>  $ pop          : num  8425333 9240934 10267083 11537966 13079460 ...\n#>  $ gdpPercap    : num  779 821 853 836 740 ...\n#>  $ country_hun  : Factor w/ 142 levels \"Afganisztán\",..: 1 1 1 1 1 1 1 1 1 1 ...\n#>  $ continent_hun: Factor w/ 5 levels \"Afrika\",\"Amerika\",..: 3 3 3 3 3 3 3 3 3 3 ..."},{"path":"advanced-data-manipulation.html","id":"renaming-columns","chapter":"4 Advanced data manipulation","heading":"4.4.2 Renaming columns","text":"importing data, columns can renamed assigning new names .","code":"\nnames(gapminder_utf8)\n#> [1] \"country\"       \"continent\"     \"year\"         \n#> [4] \"lifeExp\"       \"pop\"           \"gdpPercap\"    \n#> [7] \"country_hun\"   \"continent_hun\"\nnames(gapminder_utf8)[1] <- \"orszag\"\nnames(gapminder_utf8)[2] <- \"kontinens\"\nnames(gapminder_utf8)\n#> [1] \"orszag\"        \"kontinens\"     \"year\"         \n#> [4] \"lifeExp\"       \"pop\"           \"gdpPercap\"    \n#> [7] \"country_hun\"   \"continent_hun\"\n\nnames(gapminder_utf8)\n#> [1] \"orszag\"        \"kontinens\"     \"year\"         \n#> [4] \"lifeExp\"       \"pop\"           \"gdpPercap\"    \n#> [7] \"country_hun\"   \"continent_hun\"\nnames(gapminder_utf8)[7:8] <- c(\"orszag_hun\", \"kontinens_hun\")\nnames(gapminder_utf8)\n#> [1] \"orszag\"        \"kontinens\"     \"year\"         \n#> [4] \"lifeExp\"       \"pop\"           \"gdpPercap\"    \n#> [7] \"orszag_hun\"    \"kontinens_hun\""},{"path":"advanced-data-manipulation.html","id":"insert-and-derive-new-columns","chapter":"4 Advanced data manipulation","heading":"4.4.3 Insert and derive new columns","text":"","code":"\n# Here's a data set of 1,000 most popular movies on IMDB in the last 10 years. \n# https://www.kaggle.com/PromptCloudHQ/imdb-data/version/1\nmov <- read.table(file = \"data/IMDB-Movie-Data.csv\", header = T, sep = \",\", dec = \".\", fileEncoding = \"UTF-8\", quote = \"\\\"\",\n                  comment.char = \"\")\nstr(mov)\n#> 'data.frame':    1000 obs. of  12 variables:\n#>  $ Rank              : int  1 2 3 4 5 6 7 8 9 10 ...\n#>  $ Title             : chr  \"Guardians of the Galaxy\" \"Prometheus\" \"Split\" \"Sing\" ...\n#>  $ Genre             : chr  \"Action,Adventure,Sci-Fi\" \"Adventure,Mystery,Sci-Fi\" \"Horror,Thriller\" \"Animation,Comedy,Family\" ...\n#>  $ Description       : chr  \"A group of intergalactic criminals are forced to work together to stop a fanatical warrior from taking control \"| __truncated__ \"Following clues to the origin of mankind, a team finds a structure on a distant moon, but they soon realize the\"| __truncated__ \"Three girls are kidnapped by a man with a diagnosed 23 distinct personalities. They must try to escape before t\"| __truncated__ \"In a city of humanoid animals, a hustling theater impresario's attempt to save his theater with a singing compe\"| __truncated__ ...\n#>  $ Director          : chr  \"James Gunn\" \"Ridley Scott\" \"M. Night Shyamalan\" \"Christophe Lourdelet\" ...\n#>  $ Actors            : chr  \"Chris Pratt, Vin Diesel, Bradley Cooper, Zoe Saldana\" \"Noomi Rapace, Logan Marshall-Green, Michael Fassbender, Charlize Theron\" \"James McAvoy, Anya Taylor-Joy, Haley Lu Richardson, Jessica Sula\" \"Matthew McConaughey,Reese Witherspoon, Seth MacFarlane, Scarlett Johansson\" ...\n#>  $ Year              : int  2014 2012 2016 2016 2016 2016 2016 2016 2016 2016 ...\n#>  $ Runtime..Minutes. : int  121 124 117 108 123 103 128 89 141 116 ...\n#>  $ Rating            : num  8.1 7 7.3 7.2 6.2 6.1 8.3 6.4 7.1 7 ...\n#>  $ Votes             : int  757074 485820 157606 60545 393727 56036 258682 2490 7188 192177 ...\n#>  $ Revenue..Millions.: num  333 126 138 270 325 ...\n#>  $ Metascore         : int  76 65 62 59 40 42 93 71 78 41 ...\nnames(mov) <- c('Rank', 'Title', 'Genre', 'Description', 'Director', 'Actors', 'Year', \n                'Runtime', 'Rating', 'Votes', 'Revenue', 'Metascore')"},{"path":"advanced-data-manipulation.html","id":"inserting-a-new-column","chapter":"4 Advanced data manipulation","heading":"4.4.4 Inserting a new column","text":"insert new column, index data frame new column name assign values.","code":"\n# adding a new column known as example\nmovies <- mov[,c(2, 7, 11, 12)]\nset.seed(123)\nmovies$Example <- sample(x = 1000)\nhead(movies)\n#>                     Title Year Revenue Metascore Example\n#> 1 Guardians of the Galaxy 2014  333.13        76     415\n#> 2              Prometheus 2012  126.46        65     463\n#> 3                   Split 2016  138.12        62     179\n#> 4                    Sing 2016  270.32        59     526\n#> 5           Suicide Squad 2016  325.02        40     195\n#> 6          The Great Wall 2016   45.13        42     938"},{"path":"advanced-data-manipulation.html","id":"duplicating-a-column","chapter":"4 Advanced data manipulation","heading":"4.4.4.1 Duplicating a column","text":"Duplicating column like inserting new one. simply select assign new name.","code":"\nmovies <- mov[, c(2, 7, 11, 12)]\nmovies$Metascore.2 <- movies$Metascore\nhead(movies)\n#>                     Title Year Revenue Metascore\n#> 1 Guardians of the Galaxy 2014  333.13        76\n#> 2              Prometheus 2012  126.46        65\n#> 3                   Split 2016  138.12        62\n#> 4                    Sing 2016  270.32        59\n#> 5           Suicide Squad 2016  325.02        40\n#> 6          The Great Wall 2016   45.13        42\n#>   Metascore.2\n#> 1          76\n#> 2          65\n#> 3          62\n#> 4          59\n#> 5          40\n#> 6          42"},{"path":"advanced-data-manipulation.html","id":"deriving-a-new-column-from-an-existing-one","chapter":"4 Advanced data manipulation","heading":"4.4.4.2 Deriving a new column from an existing one","text":"","code":"\nmovies <- mov[, c(2, 7, 9, 12)]\nmovies$Movie.Class <- \ncut(movies$Rating, \n    breaks = c(0, 5.5, 6.5, 7, 7.5, 10), \n    labels = c(\"Very Low\", \"Low\", \"Moderate\", \"High\", \"Very High\"))\nhead(movies)\n#>                     Title Year Rating Metascore Movie.Class\n#> 1 Guardians of the Galaxy 2014    8.1        76   Very High\n#> 2              Prometheus 2012    7.0        65    Moderate\n#> 3                   Split 2016    7.3        62        High\n#> 4                    Sing 2016    7.2        59        High\n#> 5           Suicide Squad 2016    6.2        40         Low\n#> 6          The Great Wall 2016    6.1        42         Low\n\n# plotting the new column\nplot(movies$Movie.Class)"},{"path":"advanced-data-manipulation.html","id":"deriving-a-new-column-from-a-calculation","chapter":"4 Advanced data manipulation","heading":"4.4.4.3 Deriving a new column from a calculation","text":"","code":"\nmovies <- mov[, c(2, 5, 7, 8, 11)]\nmovies$Rev.Run <- round(movies$Revenue/movies$Runtime, 2)\nhead(movies)\n#>                     Title             Director Year Runtime\n#> 1 Guardians of the Galaxy           James Gunn 2014     121\n#> 2              Prometheus         Ridley Scott 2012     124\n#> 3                   Split   M. Night Shyamalan 2016     117\n#> 4                    Sing Christophe Lourdelet 2016     108\n#> 5           Suicide Squad           David Ayer 2016     123\n#> 6          The Great Wall          Yimou Zhang 2016     103\n#>   Revenue Rev.Run\n#> 1  333.13    2.75\n#> 2  126.46    1.02\n#> 3  138.12    1.18\n#> 4  270.32    2.50\n#> 5  325.02    2.64\n#> 6   45.13    0.44"},{"path":"advanced-data-manipulation.html","id":"updating-a-column","chapter":"4 Advanced data manipulation","heading":"4.4.4.4 Updating a column","text":"","code":"\nmovies <- mov[,c(2, 5, 7, 9, 11, 12)]\nmovies$Director <- toupper(movies$Director)\nmovies$Title <- tolower(movies$Title)\nhead(movies)\n#>                     Title             Director Year Rating\n#> 1 guardians of the galaxy           JAMES GUNN 2014    8.1\n#> 2              prometheus         RIDLEY SCOTT 2012    7.0\n#> 3                   split   M. NIGHT SHYAMALAN 2016    7.3\n#> 4                    sing CHRISTOPHE LOURDELET 2016    7.2\n#> 5           suicide squad           DAVID AYER 2016    6.2\n#> 6          the great wall          YIMOU ZHANG 2016    6.1\n#>   Revenue Metascore\n#> 1  333.13        76\n#> 2  126.46        65\n#> 3  138.12        62\n#> 4  270.32        59\n#> 5  325.02        40\n#> 6   45.13        42"},{"path":"advanced-data-manipulation.html","id":"sorting-and-ranking","chapter":"4 Advanced data manipulation","heading":"4.4.5 Sorting and ranking","text":"","code":""},{"path":"advanced-data-manipulation.html","id":"sorting-a-data-frame","chapter":"4 Advanced data manipulation","heading":"4.4.5.1 Sorting a data frame","text":"order() function used sort data frame. takes column returns indices ascending order. reverse , use decreasing = TRUE. indices sorted, used index data frame. function order() also works character columns well multiple columns.default, NA values appear end sorted column, can changed setting na.last = FALSE appear first.","code":"\n# sorting by revenue\nmovies <- mov[, c(2, 7, 11, 12)]\nmovies_ordered <- movies[order(movies$Revenue),]\nhead(movies_ordered)\n#>                Title Year Revenue Metascore\n#> 232 A Kind of Murder 2016    0.00        50\n#> 28        Dead Awake 2016    0.01        NA\n#> 69         Wakefield 2016    0.01        61\n#> 322         Lovesong 2016    0.01        74\n#> 678      Love, Rosie 2014    0.01        44\n#> 962  Into the Forest 2015    0.01        59\ntail(movies_ordered)\n#>                              Title Year Revenue Metascore\n#> 977                    Dark Places 2015      NA        39\n#> 978                  Amateur Night 2016      NA        38\n#> 979 It's Only the End of the World 2016      NA        48\n#> 989                        Martyrs 2008      NA        89\n#> 996           Secret in Their Eyes 2015      NA        45\n#> 999                   Search Party 2014      NA        22\n\n# sort decreasing\nmovies_ordered <- movies[order(movies$Revenue, decreasing = T),]\nhead(movies_ordered)\n#>                                         Title Year Revenue\n#> 51 Star Wars: Episode VII - The Force Awakens 2015  936.63\n#> 88                                     Avatar 2009  760.51\n#> 86                             Jurassic World 2015  652.18\n#> 77                               The Avengers 2012  623.28\n#> 55                            The Dark Knight 2008  533.32\n#> 13                                  Rogue One 2016  532.17\n#>    Metascore\n#> 51        81\n#> 88        83\n#> 86        59\n#> 77        69\n#> 55        82\n#> 13        65\ntail(movies_ordered)\n#>                              Title Year Revenue Metascore\n#> 977                    Dark Places 2015      NA        39\n#> 978                  Amateur Night 2016      NA        38\n#> 979 It's Only the End of the World 2016      NA        48\n#> 989                        Martyrs 2008      NA        89\n#> 996           Secret in Their Eyes 2015      NA        45\n#> 999                   Search Party 2014      NA        22\n\n# sort decreasing using the negative sign\nmovies_ordered <- movies[order(-movies$Revenue),]\nhead(movies_ordered)\n#>                                         Title Year Revenue\n#> 51 Star Wars: Episode VII - The Force Awakens 2015  936.63\n#> 88                                     Avatar 2009  760.51\n#> 86                             Jurassic World 2015  652.18\n#> 77                               The Avengers 2012  623.28\n#> 55                            The Dark Knight 2008  533.32\n#> 13                                  Rogue One 2016  532.17\n#>    Metascore\n#> 51        81\n#> 88        83\n#> 86        59\n#> 77        69\n#> 55        82\n#> 13        65\ntail(movies_ordered)\n#>                              Title Year Revenue Metascore\n#> 977                    Dark Places 2015      NA        39\n#> 978                  Amateur Night 2016      NA        38\n#> 979 It's Only the End of the World 2016      NA        48\n#> 989                        Martyrs 2008      NA        89\n#> 996           Secret in Their Eyes 2015      NA        45\n#> 999                   Search Party 2014      NA        22\n# placing NA at the beginning\nmovies_ordered <- movies[order(movies$Revenue, na.last = FALSE),]\nhead(movies_ordered)\n#>                      Title Year Revenue Metascore\n#> 8                 Mindhorn 2016      NA        71\n#> 23          Hounds of Love 2016      NA        72\n#> 26         Paris pieds nus 2016      NA        NA\n#> 40               5- 25- 77 2007      NA        NA\n#> 43 Don't Fuck in the Woods 2016      NA        NA\n#> 48                  Fallen 2016      NA        NA\ntail(movies_ordered)\n#>                                         Title Year Revenue\n#> 13                                  Rogue One 2016  532.17\n#> 55                            The Dark Knight 2008  533.32\n#> 77                               The Avengers 2012  623.28\n#> 86                             Jurassic World 2015  652.18\n#> 88                                     Avatar 2009  760.51\n#> 51 Star Wars: Episode VII - The Force Awakens 2015  936.63\n#>    Metascore\n#> 13        65\n#> 55        82\n#> 77        69\n#> 86        59\n#> 88        83\n#> 51        81\n\n# sorting on multiple columns\nmovies_ordered <- movies[order(movies$Metascore, movies$Revenue, decreasing = T),]\nhead(movies_ordered, 10)\n#>                     Title Year Revenue Metascore\n#> 657               Boyhood 2014   25.36       100\n#> 42              Moonlight 2016   27.85        99\n#> 231       Pan's Labyrinth 2006   37.62        98\n#> 510               Gravity 2013  274.08        96\n#> 490           Ratatouille 2007  206.44        96\n#> 112      12 Years a Slave 2013   56.67        96\n#> 22  Manchester by the Sea 2016   47.70        96\n#> 325    The Social Network 2010   96.92        95\n#> 407      Zero Dark Thirty 2012   95.72        95\n#> 502                 Carol 2015    0.25        95"},{"path":"advanced-data-manipulation.html","id":"ranking","chapter":"4 Advanced data manipulation","heading":"4.4.6 Ranking","text":"function rank() ranks column values. ascending order can reversed placing negative sign front ranking column decreasing argument case order() function.decreasing argument rank(), hence chance performing decreasing rank use negative sign.","code":"\n# returning ranks by revenue\nrank(movies$Revenue)[1:10]\n#>  [1] 841 678 702 819 839 419 724 873 182 623\n\n# adding a rank to the data frame\nmovies <- mov[, c(2, 7, 11, 12)]\nmovies$Ranking <- rank(movies$Revenue)\nhead(movies)\n#>                     Title Year Revenue Metascore Ranking\n#> 1 Guardians of the Galaxy 2014  333.13        76     841\n#> 2              Prometheus 2012  126.46        65     678\n#> 3                   Split 2016  138.12        62     702\n#> 4                    Sing 2016  270.32        59     819\n#> 5           Suicide Squad 2016  325.02        40     839\n#> 6          The Great Wall 2016   45.13        42     419\n\n# sorting by rank\nmovies <- mov[, c(2, 7, 11, 12)]\nmovies$Ranking <- rank(movies$Revenue)\nmovies <- movies[order(movies$Ranking), ]\nhead(movies)\n#>                Title Year Revenue Metascore Ranking\n#> 232 A Kind of Murder 2016    0.00        50       1\n#> 28        Dead Awake 2016    0.01        NA       4\n#> 69         Wakefield 2016    0.01        61       4\n#> 322         Lovesong 2016    0.01        74       4\n#> 678      Love, Rosie 2014    0.01        44       4\n#> 962  Into the Forest 2015    0.01        59       4\n\n# placing NA values at the beginning\nmovies <- mov[, c(2, 7, 11, 12)]\nmovies$Ranking <- rank(movies$Revenue, na.last = F)\nmovies <- movies[order(movies$Ranking), ]\nhead(movies)\n#>                      Title Year Revenue Metascore Ranking\n#> 8                 Mindhorn 2016      NA        71       1\n#> 23          Hounds of Love 2016      NA        72       2\n#> 26         Paris pieds nus 2016      NA        NA       3\n#> 40               5- 25- 77 2007      NA        NA       4\n#> 43 Don't Fuck in the Woods 2016      NA        NA       5\n#> 48                  Fallen 2016      NA        NA       6\n# performing a decreasing rank\nmovies <- mov[, c(2, 7, 8, 11)]\nmovies$Ranking <- rank(-movies$Revenue)\nmovies <- movies[order(movies$Ranking), ]\nhead(movies)\n#>                                         Title Year Runtime\n#> 51 Star Wars: Episode VII - The Force Awakens 2015     136\n#> 88                                     Avatar 2009     162\n#> 86                             Jurassic World 2015     124\n#> 77                               The Avengers 2012     143\n#> 55                            The Dark Knight 2008     152\n#> 13                                  Rogue One 2016     133\n#>    Revenue Ranking\n#> 51  936.63       1\n#> 88  760.51       2\n#> 86  652.18       3\n#> 77  623.28       4\n#> 55  533.32       5\n#> 13  532.17       6"},{"path":"advanced-data-manipulation.html","id":"splitting-and-merging-columns","chapter":"4 Advanced data manipulation","heading":"4.4.7 Splitting and Merging columns","text":"","code":""},{"path":"advanced-data-manipulation.html","id":"splitting-columns","chapter":"4 Advanced data manipulation","heading":"4.4.7.1 Splitting columns","text":"split data frame, followingselect column concerned pass function strsplit() together string split . return listusing function .call('rbind', dfs) convert list data framerename columns new data framefinally using cbind(), combine new data frame original one","code":"\n# Airports are ranked by travellers and experts based on various measures.\n# https://www.kaggle.com/jonahmary17/airports\n\n# reading data\nbusiestAirports <- read.table(file = \"data/busiestAirports.csv\", \n                              header = T, \n                              sep=\",\", \n                              dec = \".\", \n                              quote = \"\\\"\")\n\nbusiestAirports <- busiestAirports[-c(1, 2, 3, 4, 8)]\nhead(busiestAirports, 3)\n#>   code.iata.icao.                 location\n#> 1        ATL/KATL         Atlanta, Georgia\n#> 2        PEK/ZBAA Chaoyang-Shunyi, Beijing\n#> 3        DXB/OMDB           Garhoud, Dubai\n#>                country\n#> 1        United States\n#> 2                China\n#> 3 United Arab Emirates\n\n# splitting column\nstrsplit(busiestAirports$code.iata.icao.,'/')[1:3]\n#> [[1]]\n#> [1] \"ATL\"  \"KATL\"\n#> \n#> [[2]]\n#> [1] \"PEK\"  \"ZBAA\"\n#> \n#> [[3]]\n#> [1] \"DXB\"  \"OMDB\"\n\n# converting to a data frame\niata_icao <- \ndata.frame(do.call('rbind', strsplit(busiestAirports$code.iata.icao., '/')))\nhead(iata_icao, 3)\n#>    X1   X2\n#> 1 ATL KATL\n#> 2 PEK ZBAA\n#> 3 DXB OMDB\n\n# renaming columns\nnames(iata_icao) <- c('iata', 'icao')\nhead(iata_icao, 3)\n#>   iata icao\n#> 1  ATL KATL\n#> 2  PEK ZBAA\n#> 3  DXB OMDB\n\n# combining both data frames\nbusiest_Airports <- cbind(busiestAirports[-1], iata_icao)\nhead(busiest_Airports)\n#>                   location              country iata icao\n#> 1         Atlanta, Georgia        United States  ATL KATL\n#> 2 Chaoyang-Shunyi, Beijing                China  PEK ZBAA\n#> 3           Garhoud, Dubai United Arab Emirates  DXB OMDB\n#> 4  Los Angeles, California        United States  LAX KLAX\n#> 5               Ota, Tokyo                Japan  HND RJTT\n#> 6        Chicago, Illinois        United States  ORD KORD"},{"path":"advanced-data-manipulation.html","id":"merging-columns","chapter":"4 Advanced data manipulation","heading":"4.4.8 Merging columns","text":"function paste() used merge columns.","code":"\n# merging iata and icao into iata_icao\nbusiest_Airports$iata_icao <- \npaste(busiest_Airports$iata, busiest_Airports$icao, sep = '-')\nhead(busiest_Airports)\n#>                   location              country iata icao\n#> 1         Atlanta, Georgia        United States  ATL KATL\n#> 2 Chaoyang-Shunyi, Beijing                China  PEK ZBAA\n#> 3           Garhoud, Dubai United Arab Emirates  DXB OMDB\n#> 4  Los Angeles, California        United States  LAX KLAX\n#> 5               Ota, Tokyo                Japan  HND RJTT\n#> 6        Chicago, Illinois        United States  ORD KORD\n#>   iata_icao\n#> 1  ATL-KATL\n#> 2  PEK-ZBAA\n#> 3  DXB-OMDB\n#> 4  LAX-KLAX\n#> 5  HND-RJTT\n#> 6  ORD-KORD"},{"path":"advanced-data-manipulation.html","id":"deleting-columns","chapter":"4 Advanced data manipulation","heading":"4.4.9 Deleting columns","text":"special function delete columns [ NULL can used drop unwanted columns.","code":"\nstr(gapminder_cp1250)\n#> 'data.frame':    1698 obs. of  8 variables:\n#>  $ country      : chr  \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ...\n#>  $ continent    : chr  \"Asia\" \"Asia\" \"Asia\" \"Asia\" ...\n#>  $ year         : int  1952 1957 1962 1967 1972 1977 1982 1987 1992 1997 ...\n#>  $ lifeExp      : num  28.8 30.3 32 34 36.1 ...\n#>  $ pop          : int  8425333 9240934 10267083 11537966 13079460 14880372 12881816 13867957 16317921 22227415 ...\n#>  $ gdpPercap    : num  779 821 853 836 740 ...\n#>  $ country_hun  : chr  \"Afganisztán\" \"Afganisztán\" \"Afganisztán\" \"Afganisztán\" ...\n#>  $ continent_hun: chr  \"Ázsia\" \"Ázsia\" \"Ázsia\" \"Ázsia\" ...\ngapminder_cp1250$pop <- NULL\nstr(gapminder_cp1250)\n#> 'data.frame':    1698 obs. of  7 variables:\n#>  $ country      : chr  \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ...\n#>  $ continent    : chr  \"Asia\" \"Asia\" \"Asia\" \"Asia\" ...\n#>  $ year         : int  1952 1957 1962 1967 1972 1977 1982 1987 1992 1997 ...\n#>  $ lifeExp      : num  28.8 30.3 32 34 36.1 ...\n#>  $ gdpPercap    : num  779 821 853 836 740 ...\n#>  $ country_hun  : chr  \"Afganisztán\" \"Afganisztán\" \"Afganisztán\" \"Afganisztán\" ...\n#>  $ continent_hun: chr  \"Ázsia\" \"Ázsia\" \"Ázsia\" \"Ázsia\" ...\n\nstr(gapminder_cp1250)\n#> 'data.frame':    1698 obs. of  7 variables:\n#>  $ country      : chr  \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ...\n#>  $ continent    : chr  \"Asia\" \"Asia\" \"Asia\" \"Asia\" ...\n#>  $ year         : int  1952 1957 1962 1967 1972 1977 1982 1987 1992 1997 ...\n#>  $ lifeExp      : num  28.8 30.3 32 34 36.1 ...\n#>  $ gdpPercap    : num  779 821 853 836 740 ...\n#>  $ country_hun  : chr  \"Afganisztán\" \"Afganisztán\" \"Afganisztán\" \"Afganisztán\" ...\n#>  $ continent_hun: chr  \"Ázsia\" \"Ázsia\" \"Ázsia\" \"Ázsia\" ...\ngapminder_cp1250 <- gapminder_cp1250[, c(1, 2, 5, 6)]\nstr(gapminder_cp1250)\n#> 'data.frame':    1698 obs. of  4 variables:\n#>  $ country    : chr  \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ...\n#>  $ continent  : chr  \"Asia\" \"Asia\" \"Asia\" \"Asia\" ...\n#>  $ gdpPercap  : num  779 821 853 836 740 ...\n#>  $ country_hun: chr  \"Afganisztán\" \"Afganisztán\" \"Afganisztán\" \"Afganisztán\" ..."},{"path":"advanced-data-manipulation.html","id":"manipulating-rows","chapter":"4 Advanced data manipulation","heading":"4.5 Manipulating Rows","text":"","code":""},{"path":"advanced-data-manipulation.html","id":"adding-rows","chapter":"4 Advanced data manipulation","heading":"4.5.1 Adding rows","text":"","code":""},{"path":"advanced-data-manipulation.html","id":"adding-rows-by-assignment","chapter":"4 Advanced data manipulation","heading":"4.5.1.1 Adding rows by assignment","text":"function rbind() can combine list vector data frame. Generally, avoid using vectors may change data type data frame.","code":"\nmovies <- mov[, c(2, 5, 7, 9, 11, 12)]\ntail(movies, 3)\n#>                       Title         Director Year Rating\n#> 998  Step Up 2: The Streets       Jon M. Chu 2008    6.2\n#> 999            Search Party   Scot Armstrong 2014    5.6\n#> 1000             Nine Lives Barry Sonnenfeld 2016    5.3\n#>      Revenue Metascore\n#> 998    58.01        50\n#> 999       NA        22\n#> 1000   19.64        11\n\n# inserting rows\nmovies[1001,] <- c(\"the big g\", \"goro lovic\", 2015, 9.9, 1000, 100)\nmovies[1002,] <- c(\"luv of my life\", \"nema lovic\", 2016, 7.9, 150, 65)\nmovies[1003,] <- c(\"everyday\", \"goro lovic\", 2014, 4.4, 170, 40)\ntail(movies)\n#>                       Title         Director Year Rating\n#> 998  Step Up 2: The Streets       Jon M. Chu 2008    6.2\n#> 999            Search Party   Scot Armstrong 2014    5.6\n#> 1000             Nine Lives Barry Sonnenfeld 2016    5.3\n#> 1001              the big g       goro lovic 2015    9.9\n#> 1002         luv of my life       nema lovic 2016    7.9\n#> 1003               everyday       goro lovic 2014    4.4\n#>      Revenue Metascore\n#> 998    58.01        50\n#> 999     <NA>        22\n#> 1000   19.64        11\n#> 1001    1000       100\n#> 1002     150        65\n#> 1003     170        40\n\n# using nrow\nmovies <- mov[, c(2, 5, 7, 9, 11, 12)]\nmovies[nrow(movies) + 1,] <- c(\"the big g\", \"goro lovic\", 2015, 9.9, 1000, 100)\nmovies[nrow(movies) + 1,] <- c(\"luv of my life\", \"nema lovic\", 2016, 7.9, 150, 65)\nmovies[nrow(movies) + 1,] <- c(\"everyday\", \"goro lovic\", 2014, 4.4, 170, 40)\ntail(movies)\n#>                       Title         Director Year Rating\n#> 998  Step Up 2: The Streets       Jon M. Chu 2008    6.2\n#> 999            Search Party   Scot Armstrong 2014    5.6\n#> 1000             Nine Lives Barry Sonnenfeld 2016    5.3\n#> 1001              the big g       goro lovic 2015    9.9\n#> 1002         luv of my life       nema lovic 2016    7.9\n#> 1003               everyday       goro lovic 2014    4.4\n#>      Revenue Metascore\n#> 998    58.01        50\n#> 999     <NA>        22\n#> 1000   19.64        11\n#> 1001    1000       100\n#> 1002     150        65\n#> 1003     170        40"},{"path":"advanced-data-manipulation.html","id":"adding-rows-using-rbind","chapter":"4 Advanced data manipulation","heading":"4.5.1.2 Adding rows using rbind()","text":"","code":"\n# binding a list to a data frame\nmovies <- mov[, c(2, 5, 7, 9, 11, 12)]\nmovies <- rbind(movies, list(\"the big g\", \"goro lovic\", 2015, 9.9, 1000, 100))\nmovies <- rbind(movies, list(\"luv of my life\", \"nema lovic\", 2016, 7.9, 150, 65))\nmovies <- rbind(movies, list(\"everyday\", \"goro lovic\", 2014, 4.4, 170, 40))\ntail(movies)\n#>                       Title         Director Year Rating\n#> 998  Step Up 2: The Streets       Jon M. Chu 2008    6.2\n#> 999            Search Party   Scot Armstrong 2014    5.6\n#> 1000             Nine Lives Barry Sonnenfeld 2016    5.3\n#> 1001              the big g       goro lovic 2015    9.9\n#> 1002         luv of my life       nema lovic 2016    7.9\n#> 1003               everyday       goro lovic 2014    4.4\n#>      Revenue Metascore\n#> 998    58.01        50\n#> 999       NA        22\n#> 1000   19.64        11\n#> 1001 1000.00       100\n#> 1002  150.00        65\n#> 1003  170.00        40\n\nmovies <- mov[, c(2, 5, 7, 9, 11, 12)]\nsapply(movies, class)\n#>       Title    Director        Year      Rating     Revenue \n#> \"character\" \"character\"   \"integer\"   \"numeric\"   \"numeric\" \n#>   Metascore \n#>   \"integer\"\n\n# using a vector\nmovies <- rbind(movies, c(\"the big g\", \"goro lovic\", 2015, 9.9, 1000, 100))\nsapply(movies, class)\n#>       Title    Director        Year      Rating     Revenue \n#> \"character\" \"character\" \"character\" \"character\" \"character\" \n#>   Metascore \n#> \"character\""},{"path":"advanced-data-manipulation.html","id":"adding-rows-using-do.call","chapter":"4 Advanced data manipulation","heading":"4.5.1.3 Adding rows using do.call()","text":"function .call('rbind', dfs) combines list data frames, list, vectors. , avoid using vectors may change data type data frames.","code":"\nmovies <- subset(mov, select = c(2, 5, 7, 9, 11, 12))\nmovies <- do.call('rbind', list(movies,\n                                list(\"the big g\", \"goro lovic\", 2015, 9.9, 1000, 100), \n                                list(\"luv of my life\", \"nema lovic\", 2016, 7.9, 150, 65), \n                                list(\"everyday\", \"goro lovic\", 2014, 4.4, 170, 40)))\ntail(movies)\n#>                       Title         Director Year Rating\n#> 998  Step Up 2: The Streets       Jon M. Chu 2008    6.2\n#> 999            Search Party   Scot Armstrong 2014    5.6\n#> 1000             Nine Lives Barry Sonnenfeld 2016    5.3\n#> 1001              the big g       goro lovic 2015    9.9\n#> 1002         luv of my life       nema lovic 2016    7.9\n#> 1003               everyday       goro lovic 2014    4.4\n#>      Revenue Metascore\n#> 998    58.01        50\n#> 999       NA        22\n#> 1000   19.64        11\n#> 1001 1000.00       100\n#> 1002  150.00        65\n#> 1003  170.00        40"},{"path":"advanced-data-manipulation.html","id":"updating-rows-of-data","chapter":"4 Advanced data manipulation","heading":"4.5.2 Updating rows of data","text":"update row, simply select give new list values. Vectors can used also avoided may change data type data frame.","code":"\nmovies <- mov[, c(1, 2, 5, 7, 9, 11, 12)]\nmovies[6,]\n#>   Rank          Title    Director Year Rating Revenue\n#> 6    6 The Great Wall Yimou Zhang 2016    6.1   45.13\n#>   Metascore\n#> 6        42\n\n# updating a row by indexing\nmovies[6,] <- list(6, 'I am coming home', 'goro lovic', 2020, 9.8, 850, 85)\nmovies[6,]\n#>   Rank            Title   Director Year Rating Revenue\n#> 6    6 I am coming home goro lovic 2020    9.8     850\n#>   Metascore\n#> 6        85\n\n# updating a row by filtering\nmovies <- mov[, c(1, 2, 5, 7, 9, 11, 12)]\nmovies[movies$Rank == 6,] <- list(6, 'I am coming home', 'goro lovic', 2020, 9.8, 850, 85)\nmovies[movies$Rank == 6,]\n#>   Rank            Title   Director Year Rating Revenue\n#> 6    6 I am coming home goro lovic 2020    9.8     850\n#>   Metascore\n#> 6        85"},{"path":"advanced-data-manipulation.html","id":"updating-a-single-value","chapter":"4 Advanced data manipulation","heading":"4.5.3 Updating a single value","text":"update single value, select subsetting assign new value.","code":"\nmovies <- mov[, c(1, 2, 5, 7, 9, 11, 12)]\nmovies[movies$Director == 'Christopher Nolan',]\n#>     Rank                 Title          Director Year\n#> 37    37          Interstellar Christopher Nolan 2014\n#> 55    55       The Dark Knight Christopher Nolan 2008\n#> 65    65          The Prestige Christopher Nolan 2006\n#> 81    81             Inception Christopher Nolan 2010\n#> 125  125 The Dark Knight Rises Christopher Nolan 2012\n#>     Rating Revenue Metascore\n#> 37     8.6  187.99        74\n#> 55     9.0  533.32        82\n#> 65     8.5   53.08        66\n#> 81     8.8  292.57        74\n#> 125    8.5  448.13        78\n\n# changing from 'Christopher Nolan' to 'C Nolan' \nmovies[movies$Director == 'Christopher Nolan', 'Director'] <- 'C Nolan'\nmovies[c(37, 55, 65, 81, 125),]\n#>     Rank                 Title Director Year Rating Revenue\n#> 37    37          Interstellar  C Nolan 2014    8.6  187.99\n#> 55    55       The Dark Knight  C Nolan 2008    9.0  533.32\n#> 65    65          The Prestige  C Nolan 2006    8.5   53.08\n#> 81    81             Inception  C Nolan 2010    8.8  292.57\n#> 125  125 The Dark Knight Rises  C Nolan 2012    8.5  448.13\n#>     Metascore\n#> 37         74\n#> 55         82\n#> 65         66\n#> 81         74\n#> 125        78"},{"path":"advanced-data-manipulation.html","id":"randomly-selecting-rows","chapter":"4 Advanced data manipulation","heading":"4.5.4 Randomly selecting rows","text":"select random sample rows, use function sample().","code":"\n# selecting 10 random rows\nmovies <- mov[, c(2, 7, 11, 12)]\nmovies[sample(x = nrow(movies), size = 10), ]\n#>                    Title Year Revenue Metascore\n#> 535      A Quiet Passion 2016    1.08        77\n#> 471    American Gangster 2007  130.13        76\n#> 728      The Illusionist 2006   39.83        68\n#> 789 Hotel Transylvania 2 2015  169.69        44\n#> 978        Amateur Night 2016      NA        38\n#> 275            Ballerina 2016      NA        NA\n#> 905              RoboCop 2014   58.61        52\n#> 723            Grown Ups 2010  162.00        30\n#> 958         End of Watch 2012   40.98        68\n#> 211          San Andreas 2015  155.18        43"},{"path":"advanced-data-manipulation.html","id":"deleting-rows","chapter":"4 Advanced data manipulation","heading":"4.5.5 Deleting rows","text":"special function delete rows, can filtered using [.","code":"\nmovies_without_first10 <- movies[11:nrow(movies), ]\nnrow(movies)\n#> [1] 1000\nnrow(movies_without_first10)\n#> [1] 990"},{"path":"advanced-data-manipulation.html","id":"sql-like-joins","chapter":"4 Advanced data manipulation","heading":"4.6 SQL like joins","text":"basic level four types SQL joins:Inner join: returns rows matched data framesLeft join (left outer join): returns rows found left data frame irrespective whether matched rows right data frame. rows match values right data frames, NA values returned instead.Right join (right outer join): reverse left join, returns rows found right data frame irrespective whether matched left data frame.Outer join (full outer join): returns rows data frames irrespective whether matched ","code":""},{"path":"advanced-data-manipulation.html","id":"inner-join","chapter":"4 Advanced data manipulation","heading":"4.6.1 Inner join","text":"","code":"\n# preparing data\nemployees <- data.frame(\n  name = c('john', 'mary', 'david', 'paul', 'susan', 'cynthia', 'Joss', 'dennis'),\n  age = c(45, 55, 35, 58, 40, 30, 39, 25),\n  gender = c('m', 'f', 'm', 'm', 'f', 'f', 'm', 'm'),\n  salary =c(40000, 50000, 35000, 25000, 48000, 32000, 20000, 45000),\n  department = c('commercial', 'production', NA, 'human resources', \n                 'commercial', 'commercial', 'production', NA))\nemployees\n#>      name age gender salary      department\n#> 1    john  45      m  40000      commercial\n#> 2    mary  55      f  50000      production\n#> 3   david  35      m  35000            <NA>\n#> 4    paul  58      m  25000 human resources\n#> 5   susan  40      f  48000      commercial\n#> 6 cynthia  30      f  32000      commercial\n#> 7    Joss  39      m  20000      production\n#> 8  dennis  25      m  45000            <NA>\ndepartments <- data.frame(\n  department = c('commercial', 'human resources', 'production', 'finance', 'maintenance'),\n  location = c('washington', 'london', 'paris', 'dubai', 'dublin'))\ndepartments\n#>        department   location\n#> 1      commercial washington\n#> 2 human resources     london\n#> 3      production      paris\n#> 4         finance      dubai\n#> 5     maintenance     dublin\n\n# returns only rows that are matched in both data frames\nmerge(employees, departments, by = \"department\")\n#>        department    name age gender salary   location\n#> 1      commercial    john  45      m  40000 washington\n#> 2      commercial   susan  40      f  48000 washington\n#> 3      commercial cynthia  30      f  32000 washington\n#> 4 human resources    paul  58      m  25000     london\n#> 5      production    mary  55      f  50000      paris\n#> 6      production    Joss  39      m  20000      paris"},{"path":"advanced-data-manipulation.html","id":"left-join","chapter":"4 Advanced data manipulation","heading":"4.6.2 Left join","text":"perform left join, argument .x = TRUE used.","code":"\n# returns all the values of the left data frame\nmerge(employees, departments, by = \"department\", all.x = TRUE)\n#>        department    name age gender salary   location\n#> 1      commercial    john  45      m  40000 washington\n#> 2      commercial   susan  40      f  48000 washington\n#> 3      commercial cynthia  30      f  32000 washington\n#> 4 human resources    paul  58      m  25000     london\n#> 5      production    mary  55      f  50000      paris\n#> 6      production    Joss  39      m  20000      paris\n#> 7            <NA>   david  35      m  35000       <NA>\n#> 8            <NA>  dennis  25      m  45000       <NA>"},{"path":"advanced-data-manipulation.html","id":"right-join","chapter":"4 Advanced data manipulation","heading":"4.6.3 Right join","text":"perform right join, argument .y = TRUE used.","code":"\n# returns all the values of the right table\nmerge(employees, departments, by = \"department\", all.y = TRUE)\n#>        department    name age gender salary   location\n#> 1      commercial    john  45      m  40000 washington\n#> 2      commercial   susan  40      f  48000 washington\n#> 3      commercial cynthia  30      f  32000 washington\n#> 4         finance    <NA>  NA   <NA>     NA      dubai\n#> 5 human resources    paul  58      m  25000     london\n#> 6     maintenance    <NA>  NA   <NA>     NA     dublin\n#> 7      production    mary  55      f  50000      paris\n#> 8      production    Joss  39      m  20000      paris\n\n# reversing the tables in the right join produces the same results as the left join\nmerge(departments, employees , by = \"department\", all.y = TRUE)\n#>        department   location    name age gender salary\n#> 1      commercial washington    john  45      m  40000\n#> 2      commercial washington   susan  40      f  48000\n#> 3      commercial washington cynthia  30      f  32000\n#> 4 human resources     london    paul  58      m  25000\n#> 5      production      paris    mary  55      f  50000\n#> 6      production      paris    Joss  39      m  20000\n#> 7            <NA>       <NA>   david  35      m  35000\n#> 8            <NA>       <NA>  dennis  25      m  45000"},{"path":"advanced-data-manipulation.html","id":"full-outer-join","chapter":"4 Advanced data manipulation","heading":"4.6.4 Full outer join","text":"perform full join, argument = TRUE used.","code":"\n# returns all rows\nmerge(employees, departments, by = \"department\", all = TRUE)\n#>         department    name age gender salary   location\n#> 1       commercial    john  45      m  40000 washington\n#> 2       commercial   susan  40      f  48000 washington\n#> 3       commercial cynthia  30      f  32000 washington\n#> 4          finance    <NA>  NA   <NA>     NA      dubai\n#> 5  human resources    paul  58      m  25000     london\n#> 6      maintenance    <NA>  NA   <NA>     NA     dublin\n#> 7       production    mary  55      f  50000      paris\n#> 8       production    Joss  39      m  20000      paris\n#> 9             <NA>   david  35      m  35000       <NA>\n#> 10            <NA>  dennis  25      m  45000       <NA>"},{"path":"advanced-data-manipulation.html","id":"joining-data-frames-with-different-column-names","chapter":"4 Advanced data manipulation","heading":"4.6.5 Joining data frames with different column names","text":"arguments .x= .y= used declare joining column(s) left right data frames, respectively.","code":"\n# recreating the employee table\nemployees <- data.frame(\n  name = c('john', 'mary', 'david', 'paul', 'susan', 'cynthia', 'Joss', 'dennis'),\n  age = c(45, 55, 35, 58, 40, 30, 39, 25),\n  gender = c('m', 'f', 'm', 'm', 'f', 'f', 'm', 'm'),\n  salary =c(40000, 50000, 35000, 25000, 48000, 32000, 20000, 45000),\n  dep_name = c('commercial', 'production', NA, 'human resources', 'commercial', \n               'commercial', 'production', NA))\nhead(employees, 2)\n#>   name age gender salary   dep_name\n#> 1 john  45      m  40000 commercial\n#> 2 mary  55      f  50000 production\nhead(departments, 2)\n#>        department   location\n#> 1      commercial washington\n#> 2 human resources     london\n\n# joining on columns with different names\nmerge(employees, departments, by.x = 'dep_name', by.y = 'department')\n#>          dep_name    name age gender salary   location\n#> 1      commercial    john  45      m  40000 washington\n#> 2      commercial   susan  40      f  48000 washington\n#> 3      commercial cynthia  30      f  32000 washington\n#> 4 human resources    paul  58      m  25000     london\n#> 5      production    mary  55      f  50000      paris\n#> 6      production    Joss  39      m  20000      paris"},{"path":"advanced-data-manipulation.html","id":"joining-data-frames-on-one-more-than-one-joining-column","chapter":"4 Advanced data manipulation","heading":"4.6.6 Joining data frames on one more than one joining column","text":"data frames contain two columns name, merge() try performing join using column names.data frames columns different names join , used arguments .x= .y= specify .","code":"\n# recreating the employees table\nemployees <- data.frame(\n  name = c('john', 'mary', 'david', 'paul', 'susan', 'cynthia', 'Joss', 'dennis'),\n  age = c(45, 55, 35, 58, 40, 30, 39, 25),\n  gender = c('m', 'f', 'm', 'm', 'f', 'f', 'm', 'm'),\n  salary =c(40000, 50000, 35000, 25000, 48000, 32000, 20000, 45000),\n  department = c('commercial', 'production', NA, 'human resources', 'commercial', \n                 'commercial', 'production', NA),\n  subdepartment = c('marketing', 'production', NA, 'human resources', 'sales', 'sales', \n                    'production', NA))\nhead(employees, 2)\n#>   name age gender salary department subdepartment\n#> 1 john  45      m  40000 commercial     marketing\n#> 2 mary  55      f  50000 production    production\n\n# creating the departments? table\ndepartments <- data.frame(\n  department = c('commercial', 'commercial', 'human resources', 'production', 'finance', \n                 'finance', 'maintenance'),\n  subdepartment = c('marketing', 'sales', 'human resources', 'production', 'finance', \n                    'accounting', 'maintenance'),\n  location = c('washington', 'washington', 'london', 'paris', 'dubai', 'dubai', 'dublin')\n)\nhead(departments, 2)\n#>   department subdepartment   location\n#> 1 commercial     marketing washington\n#> 2 commercial         sales washington\n\n# because they both contain the same name, the join is performed automatically\nmerge(employees, departments)\n#>        department   subdepartment    name age gender salary\n#> 1      commercial       marketing    john  45      m  40000\n#> 2      commercial           sales   susan  40      f  48000\n#> 3      commercial           sales cynthia  30      f  32000\n#> 4 human resources human resources    paul  58      m  25000\n#> 5      production      production    mary  55      f  50000\n#> 6      production      production    Joss  39      m  20000\n#>     location\n#> 1 washington\n#> 2 washington\n#> 3 washington\n#> 4     london\n#> 5      paris\n#> 6      paris\n# specifying joining columns\nmerge(employees, departments, \n      by.x = c('department', 'subdepartment'), \n      by.y =c('department', 'subdepartment'))\n#>        department   subdepartment    name age gender salary\n#> 1      commercial       marketing    john  45      m  40000\n#> 2      commercial           sales   susan  40      f  48000\n#> 3      commercial           sales cynthia  30      f  32000\n#> 4 human resources human resources    paul  58      m  25000\n#> 5      production      production    mary  55      f  50000\n#> 6      production      production    Joss  39      m  20000\n#>     location\n#> 1 washington\n#> 2 washington\n#> 3 washington\n#> 4     london\n#> 5      paris\n#> 6      paris"},{"path":"advanced-data-manipulation.html","id":"aggregating-and-grouping-data","chapter":"4 Advanced data manipulation","heading":"4.7 Aggregating and grouping data","text":"function aggregate() groups data frame specific column value performs summarization (sum, mean, median, length, min, max, etc.) based groups. split-apply-combine, splitting data frame groups (category) applies calculation group finally combines results back together create single data frame presented output.aggregate() function , groups data frame gapminder_xlsx_2007 continent, applies sum group.Rather filtering data passing aggregate() function, can filter data directly inside aggregate() using subset= argument.+ sign used group one categorical column.function cbind() used aggregate multiple columns, problem one summarisation function can used.","code":"\n# preparing data\ngapminder_xlsx_2007 <- gapminder_xlsx[gapminder_xlsx$year == 2007, ]\nhead(gapminder_xlsx_2007)\n#>        country continent year lifeExp      pop  gdpPercap\n#> 12 Afghanistan      Asia 2007  43.828 31889923   974.5803\n#> 24     Albania    Europe 2007  76.423  3600523  5937.0295\n#> 36     Algeria    Africa 2007  72.301 33333216  6223.3675\n#> 48      Angola    Africa 2007  42.731 12420476  4797.2313\n#> 60   Argentina  Americas 2007  75.320 40301927 12779.3796\n#> 72   Australia   Oceania 2007  81.235 20434176 34435.3674\n#>    country_hun continent_hun\n#> 12 Afganisztán         Ázsia\n#> 24     Albánia        Európa\n#> 36     Algéria        Afrika\n#> 48      Angola        Afrika\n#> 60   Argentína       Amerika\n#> 72  Ausztrália       Óceánia\n\n# population by continent\naggregate(pop ~ continent, gapminder_xlsx_2007, sum)\n#>   continent        pop\n#> 1    Africa  929539692\n#> 2  Americas  898871184\n#> 3      Asia 3811953827\n#> 4    Europe  586098529\n#> 5   Oceania   24549947\naggregate(pop ~ continent, gapminder_xlsx_2007, mean)\n#>   continent       pop\n#> 1    Africa  17875763\n#> 2  Americas  35954847\n#> 3      Asia 115513752\n#> 4    Europe  19536618\n#> 5   Oceania  12274974\n# filtering with the subset argument\naggregate(pop ~ continent, gapminder_xlsx, \n          subset = year == 2007, \n          sum)\n#>   continent        pop\n#> 1    Africa  929539692\n#> 2  Americas  898871184\n#> 3      Asia 3811953827\n#> 4    Europe  586098529\n#> 5   Oceania   24549947\n# pop by continent and year\naggregate(pop ~ continent + year, \n          gapminder_xlsx, \n          subset = year %in% c(1987, 2007), \n          sum)\n#>    continent year        pop\n#> 1     Africa 1987  574834110\n#> 2   Americas 1987  682753971\n#> 3       Asia 1987 2871220762\n#> 4     Europe 1987  543094160\n#> 5    Oceania 1987   19574415\n#> 6     Africa 2007  929539692\n#> 7   Americas 2007  898871184\n#> 8       Asia 2007 3811953827\n#> 9     Europe 2007  586098529\n#> 10   Oceania 2007   24549947\n# using mean\naggregate(pop ~ continent + year, \n          gapminder_xlsx, \n          subset = year %in% c(1987, 2007), \n          mean)\n#>    continent year       pop\n#> 1     Africa 1987  11054502\n#> 2   Americas 1987  27310159\n#> 3       Asia 1987  87006690\n#> 4     Europe 1987  18103139\n#> 5    Oceania 1987   9787208\n#> 6     Africa 2007  17875763\n#> 7   Americas 2007  35954847\n#> 8       Asia 2007 115513752\n#> 9     Europe 2007  19536618\n#> 10   Oceania 2007  12274974\n# aggregating on two numeric columns (lifeExp and gdpPercap)\naggregate(cbind(lifeExp, gdpPercap) ~ continent + year, \n          gapminder_xlsx, \n          subset = year %in% c(1987, 2007), \n          mean)\n#>    continent year  lifeExp gdpPercap\n#> 1     Africa 1987 53.34479  2282.669\n#> 2   Americas 1987 68.09072  7793.400\n#> 3       Asia 1987 64.85118  7608.227\n#> 4     Europe 1987 73.64217 17214.311\n#> 5    Oceania 1987 75.32000 20448.040\n#> 6     Africa 2007 54.80604  3089.033\n#> 7   Americas 2007 73.60812 11003.032\n#> 8       Asia 2007 70.72848 12473.027\n#> 9     Europe 2007 77.64860 25054.482\n#> 10   Oceania 2007 80.71950 29810.188\n# rounding with customized function\naggregate(cbind(lifeExp, gdpPercap) ~ continent + year, \n          gapminder_xlsx, \n          subset = year %in% c(1987, 2007), \n          function(x){round(mean(x), 1)})\n#>    continent year lifeExp gdpPercap\n#> 1     Africa 1987    53.3    2282.7\n#> 2   Americas 1987    68.1    7793.4\n#> 3       Asia 1987    64.9    7608.2\n#> 4     Europe 1987    73.6   17214.3\n#> 5    Oceania 1987    75.3   20448.0\n#> 6     Africa 2007    54.8    3089.0\n#> 7   Americas 2007    73.6   11003.0\n#> 8       Asia 2007    70.7   12473.0\n#> 9     Europe 2007    77.6   25054.5\n#> 10   Oceania 2007    80.7   29810.2"},{"path":"advanced-data-manipulation.html","id":"pivoting-and-unpivoting-data","chapter":"4 Advanced data manipulation","heading":"4.8 Pivoting and unpivoting data","text":"Tabular data exist two forms: long wide. wide form ideal reporting long form ideal computer. often, performing data analysis, data wide form converted long form (unpivoting) preparing reports, data long converted wide form (pivoting).wide datalong data","code":""},{"path":"advanced-data-manipulation.html","id":"pivoting","chapter":"4 Advanced data manipulation","heading":"4.8.1 Pivoting","text":"Pivoting converts data frame rows columns.","code":""},{"path":"advanced-data-manipulation.html","id":"pivoting-using-the-reshape-package","chapter":"4 Advanced data manipulation","heading":"4.8.1.1 Pivoting using the reshape package","text":"reshape package package created restructuring aggregating data using just two functions: melt() cast().function cast() pivots data melt() unpivots data.function cast() can perform aggregation fun.aggregate= argument filtering subset argument.","code":"\n# preparing long data\ndt <- aggregate(cbind(lifeExp, gdpPercap) ~ continent + year, \n                gapminder_xlsx, \n                subset = year >= 1987, \n                mean)\nhead(dt,3)\n#>   continent year  lifeExp gdpPercap\n#> 1    Africa 1987 53.34479  2282.669\n#> 2  Americas 1987 68.09072  7793.400\n#> 3      Asia 1987 64.85118  7608.227\ntail(dt,3)\n#>    continent year  lifeExp gdpPercap\n#> 23      Asia 2007 70.72848  12473.03\n#> 24    Europe 2007 77.64860  25054.48\n#> 25   Oceania 2007 80.71950  29810.19\n\nlibrary(reshape)\n# converting from long to wide\ncast(data = dt, \n     formula = continent ~ year, \n     value = 'lifeExp')\n#>   continent     1987     1992     1997     2002     2007\n#> 1    Africa 53.34479 53.62958 53.59827 53.32523 54.80604\n#> 2  Americas 68.09072 69.56836 71.15048 72.42204 73.60812\n#> 3      Asia 64.85118 66.53721 68.02052 69.23388 70.72848\n#> 4    Europe 73.64217 74.44010 75.50517 76.70060 77.64860\n#> 5   Oceania 75.32000 76.94500 78.19000 79.74000 80.71950\n# summarization\ncast(data = gapminder_xlsx_2007, \n     formula = continent ~ year, \n     value = 'pop', \n     fun.aggregate = sum)\n#>   continent       2007\n#> 1    Africa  929539692\n#> 2  Americas  898871184\n#> 3      Asia 3811953827\n#> 4    Europe  586098529\n#> 5   Oceania   24549947\n\n# filtering with subset\ncast(data = gapminder_xlsx,\n     continent ~ year,\n     subset = year >= 1987,\n     value = 'lifeExp', \n     fun.aggregate = mean)\n#>   continent     1987     1992     1997     2002     2007\n#> 1    Africa 53.34479 53.62958 53.59827 53.32523 54.80604\n#> 2  Americas 68.09072 69.56836 71.15048 72.42204 73.60812\n#> 3      Asia 64.85118 66.53721 68.02052 69.23388 70.72848\n#> 4    Europe 73.64217 74.44010 75.50517 76.70060 77.64860\n#> 5   Oceania 75.32000 76.94500 78.19000 79.74000 80.71950\n\n# rounding numbers\ncast(data = gapminder_xlsx,\n     continent ~ year,\n     subset = year >= 1987,\n     value = 'lifeExp', \n     fun.aggregate = function(x)round(mean(x), 1))\n#>   continent 1987 1992 1997 2002 2007\n#> 1    Africa 53.3 53.6 53.6 53.3 54.8\n#> 2  Americas 68.1 69.6 71.2 72.4 73.6\n#> 3      Asia 64.9 66.5 68.0 69.2 70.7\n#> 4    Europe 73.6 74.4 75.5 76.7 77.6\n#> 5   Oceania 75.3 76.9 78.2 79.7 80.7\n\n# population by year by continent\ncast(data = gapminder_xlsx,\n     year ~ continent,\n     subset = year >= 1987,\n     value = 'pop',\n     fun.aggregate = sum)\n#>   year    Africa  Americas       Asia    Europe  Oceania\n#> 1 1987 574834110 682753971 2871220762 543094160 19574415\n#> 2 1992 659081517 739274104 3133292191 558142797 20919651\n#> 3 1997 743832984 796900410 3383285500 568944148 22241430\n#> 4 2002 833723916 849772762 3601802203 578223869 23454829\n#> 5 2007 929539692 898871184 3811953827 586098529 24549947"},{"path":"advanced-data-manipulation.html","id":"pivoting-using-the-reshape2-package","chapter":"4 Advanced data manipulation","heading":"4.8.1.2 Pivoting using the reshape2 package","text":"reshape2 package reboot reshape package.function acast() dcast() used pivot data former returning matrix later data frame.","code":"\ndt_wide <- reshape2::acast(data = dt, \n                           formula = continent ~ year, \n                           value.var = 'lifeExp')\ndt_wide\n#>              1987     1992     1997     2002     2007\n#> Africa   53.34479 53.62958 53.59827 53.32523 54.80604\n#> Americas 68.09072 69.56836 71.15048 72.42204 73.60812\n#> Asia     64.85118 66.53721 68.02052 69.23388 70.72848\n#> Europe   73.64217 74.44010 75.50517 76.70060 77.64860\n#> Oceania  75.32000 76.94500 78.19000 79.74000 80.71950\nclass(dt_wide)\n#> [1] \"matrix\" \"array\"\n\ndt_wide <- reshape2::dcast(data = dt, \n                           formula = continent ~ year, \n                           value.var = 'lifeExp')\ndt_wide\n#>   continent     1987     1992     1997     2002     2007\n#> 1    Africa 53.34479 53.62958 53.59827 53.32523 54.80604\n#> 2  Americas 68.09072 69.56836 71.15048 72.42204 73.60812\n#> 3      Asia 64.85118 66.53721 68.02052 69.23388 70.72848\n#> 4    Europe 73.64217 74.44010 75.50517 76.70060 77.64860\n#> 5   Oceania 75.32000 76.94500 78.19000 79.74000 80.71950\nclass(dt_wide)\n#> [1] \"data.frame\"\n\n# filtering by year\nreshape2::dcast(data = gapminder_xlsx[gapminder_xlsx$year >= 1987,], \n                formula = continent ~ year, \n                value.var = 'lifeExp', \n                fun.aggregate = function(x)round(mean(x), 1))\n#>   continent 1987 1992 1997 2002 2007\n#> 1    Africa 53.3 53.6 53.6 53.3 54.8\n#> 2  Americas 68.1 69.6 71.2 72.4 73.6\n#> 3      Asia 64.9 66.5 68.0 69.2 70.7\n#> 4    Europe 73.6 74.4 75.5 76.7 77.6\n#> 5   Oceania 75.3 76.9 78.2 79.7 80.7"},{"path":"advanced-data-manipulation.html","id":"unpivoting","chapter":"4 Advanced data manipulation","heading":"4.8.2 Unpivoting","text":"Unpivoting converts data frame columns rows.function melt() used unpivot data. accepts following:id.vars=: columns movedmeasure.vars=: columns move rowsbut can guess default.function name reshape reshape2.argument measure.vars=, can filter data frame.","code":"\ndt_long <- melt(dt_wide)\n#> Using continent as id variables\nhead(dt_long)\n#>   continent variable    value\n#> 1    Africa     1987 53.34479\n#> 2  Americas     1987 68.09072\n#> 3      Asia     1987 64.85118\n#> 4    Europe     1987 73.64217\n#> 5   Oceania     1987 75.32000\n#> 6    Africa     1992 53.62958\n\ndt_long <- reshape2::melt(dt_wide)\n#> Using continent as id variables\nhead(dt_long)\n#>   continent variable    value\n#> 1    Africa     1987 53.34479\n#> 2  Americas     1987 68.09072\n#> 3      Asia     1987 64.85118\n#> 4    Europe     1987 73.64217\n#> 5   Oceania     1987 75.32000\n#> 6    Africa     1992 53.62958\n# adding a variable name and filtering data\ndt_long <- melt(dt_wide, \n                id.vars = 'continent', \n                variable_name = 'Year',\n                measure.vars = c('1997', '2002', '2007'))\nhead(dt_long)\n#>   continent Year    value\n#> 1    Africa 1997 53.59827\n#> 2  Americas 1997 71.15048\n#> 3      Asia 1997 68.02052\n#> 4    Europe 1997 75.50517\n#> 5   Oceania 1997 78.19000\n#> 6    Africa 2002 53.32523\n\n# adding value, variable name, and filtering data\ndt_long <- reshape2::melt(dt_wide, \n                          id.vars = 'continent', \n                          variable.name = 'Year',\n                          value.name = 'lifeExp', \n                          measure.vars = c('1997', '2002', '2007'))\nhead(dt_long)\n#>   continent Year  lifeExp\n#> 1    Africa 1997 53.59827\n#> 2  Americas 1997 71.15048\n#> 3      Asia 1997 68.02052\n#> 4    Europe 1997 75.50517\n#> 5   Oceania 1997 78.19000\n#> 6    Africa 2002 53.32523"},{"path":"advanced-data-manipulation.html","id":"detecting-and-dealing-with-missing-values","chapter":"4 Advanced data manipulation","heading":"4.9 Detecting and dealing with missing values","text":"functions anyNA() .na() used check NA values return TRUE NA value FALSE non-NA value. former checks object contains missing value, latter checks missing values within object.Since logical can added, FALSE = 0 TRUE = 1, results .na() can added determine number NA values dataset.get total number NA values columns, function colSums() used instead addition columns rather whole data frame.get number non-NA values within column, simply reverse results .na() operator (!) subtract total number rows data frame.get number rows containing non-NA values, use function complete.cases() returns TRUE rows without NA values FALSE rows NA values. Summing result gives us number rows without NA values (complete cases). can equally reverse complete.cases() operator obtain number rows NA values subtract total number rows.Using complete.cases(), can filter either rows NA values rows without NA values.","code":"\nmovies <- mov[, c(2,7,11,12)]\nhead(movies)\n#>                     Title Year Revenue Metascore\n#> 1 Guardians of the Galaxy 2014  333.13        76\n#> 2              Prometheus 2012  126.46        65\n#> 3                   Split 2016  138.12        62\n#> 4                    Sing 2016  270.32        59\n#> 5           Suicide Squad 2016  325.02        40\n#> 6          The Great Wall 2016   45.13        42\n\n# checking if an object contains any NA\nanyNA(NA)\n#> [1] TRUE\nanyNA(list(1, 3, 5, NA))\n#> [1] TRUE\nanyNA(c(1, 3, 5, NA))\n#> [1] TRUE\n# checking if data frame contains any NA values\nanyNA(movies)\n#> [1] TRUE\napply(movies, 2, anyNA)\n#>     Title      Year   Revenue Metascore \n#>     FALSE     FALSE      TRUE      TRUE\n# checking for NA values within an object\nis.na(NA)\n#> [1] TRUE\nis.na(list(1, 3, 5, NA))\n#> [1] FALSE FALSE FALSE  TRUE\nis.na(c(1, 3, 5, NA))\n#> [1] FALSE FALSE FALSE  TRUE\nhead(is.na(movies))\n#>      Title  Year Revenue Metascore\n#> [1,] FALSE FALSE   FALSE     FALSE\n#> [2,] FALSE FALSE   FALSE     FALSE\n#> [3,] FALSE FALSE   FALSE     FALSE\n#> [4,] FALSE FALSE   FALSE     FALSE\n#> [5,] FALSE FALSE   FALSE     FALSE\n#> [6,] FALSE FALSE   FALSE     FALSE\n# number of na values in a dataset\nsum(is.na(movies))\n#> [1] 192\n\n# number of na values in each column\ncolSums(is.na(movies))\n#>     Title      Year   Revenue Metascore \n#>         0         0       128        64\n# number of non-NA values within each column\ncolSums(!is.na(movies))\n#>     Title      Year   Revenue Metascore \n#>      1000      1000       872       936\nnrow(movies) - colSums(is.na(movies))\n#>     Title      Year   Revenue Metascore \n#>      1000      1000       872       936\n# number of rows without NA values\nsum(complete.cases(movies))\n#> [1] 838\n# number of rows with one or more NA values\nsum(!complete.cases(movies))\n#> [1] 162\nnrow(movies) - sum(complete.cases(movies))\n#> [1] 162\n# selecting rows without NA\nno_na_movies <- movies[complete.cases(movies), ]\nhead(no_na_movies, 10)\n#>                                      Title Year Revenue\n#> 1                  Guardians of the Galaxy 2014  333.13\n#> 2                               Prometheus 2012  126.46\n#> 3                                    Split 2016  138.12\n#> 4                                     Sing 2016  270.32\n#> 5                            Suicide Squad 2016  325.02\n#> 6                           The Great Wall 2016   45.13\n#> 7                               La La Land 2016  151.06\n#> 9                       The Lost City of Z 2016    8.01\n#> 10                              Passengers 2016  100.01\n#> 11 Fantastic Beasts and Where to Find Them 2016  234.02\n#>    Metascore\n#> 1         76\n#> 2         65\n#> 3         62\n#> 4         59\n#> 5         40\n#> 6         42\n#> 7         93\n#> 9         78\n#> 10        41\n#> 11        66\n\n# selecting rows with NA\nna_movies <- movies[!complete.cases(movies), ]\nhead(na_movies, 10)\n#>                      Title Year Revenue Metascore\n#> 8                 Mindhorn 2016      NA        71\n#> 23          Hounds of Love 2016      NA        72\n#> 26         Paris pieds nus 2016      NA        NA\n#> 27 Bahubali: The Beginning 2015    6.50        NA\n#> 28              Dead Awake 2016    0.01        NA\n#> 40               5- 25- 77 2007      NA        NA\n#> 43 Don't Fuck in the Woods 2016      NA        NA\n#> 48                  Fallen 2016      NA        NA\n#> 50           The Last Face 2016      NA        16\n#> 62 The Autopsy of Jane Doe 2016      NA        65"},{"path":"advanced-data-manipulation.html","id":"detecting-and-dealing-with-outliers","chapter":"4 Advanced data manipulation","heading":"4.10 Detecting and dealing with outliers","text":"","code":""},{"path":"advanced-data-manipulation.html","id":"what-is-an-outlier","chapter":"4 Advanced data manipulation","heading":"4.10.1 What is an outlier?","text":"Outliers also known anomalies values deviate extremely values within group data. occur errors committed collecting recording data, performing calculations just data points extreme values.","code":""},{"path":"advanced-data-manipulation.html","id":"identifying-outlier","chapter":"4 Advanced data manipulation","heading":"4.10.2 Identifying outlier","text":"","code":""},{"path":"advanced-data-manipulation.html","id":"using-summary-statistics","chapter":"4 Advanced data manipulation","heading":"4.10.2.1 Using summary statistics","text":"first step outlier detection look summary statistics, especially minimum, maximum, median, mean. example, dataset people’s ages, maximum 200 minimum negative, problem., see median mean 10 million 44 million respectively maximum value 1.3 billion. tells us outliers since maximum value varies greatly centre data.","code":"\ngapminder_xlsx_2007 <- gapminder_xlsx[gapminder_xlsx$year == 2007, ]\nhead(gapminder_xlsx_2007)\n#>        country continent year lifeExp      pop  gdpPercap\n#> 12 Afghanistan      Asia 2007  43.828 31889923   974.5803\n#> 24     Albania    Europe 2007  76.423  3600523  5937.0295\n#> 36     Algeria    Africa 2007  72.301 33333216  6223.3675\n#> 48      Angola    Africa 2007  42.731 12420476  4797.2313\n#> 60   Argentina  Americas 2007  75.320 40301927 12779.3796\n#> 72   Australia   Oceania 2007  81.235 20434176 34435.3674\n#>    country_hun continent_hun\n#> 12 Afganisztán         Ázsia\n#> 24     Albánia        Európa\n#> 36     Algéria        Afrika\n#> 48      Angola        Afrika\n#> 60   Argentína       Amerika\n#> 72  Ausztrália       Óceánia\nsummary(gapminder_xlsx_2007$pop/1e6)\n#>      Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n#>    0.1996    4.5080   10.5175   44.0212   31.2100 1318.6831"},{"path":"advanced-data-manipulation.html","id":"using-plots","chapter":"4 Advanced data manipulation","heading":"4.10.2.2 Using plots","text":"Outliers identified using univariate plots histogram, density plot boxplot.data visualizations, boxplot relevant shows spread data outliers. boxplot reveals following:minimum value,first quantile (Q1),median (second quantile),third quantile (Q3),maximum value excluding outliers andoutliers.difference Q3 Q1 known Interquartile Range (IQR). outliers within box plot calculated value falls beyond 1.5 * IQR.function boxplot.stats() computes data used draw box plot. Using function, can get outliers.first element returned summary statistic calculated summary().last element returned outliers.Recall outliers calculated 1.5 * IQR, can changed using argument coef. default, set 1.5 can changed need .","code":"\n# plotting variable using histogram\nhist(gapminder_xlsx_2007$gdpPercap, breaks = 18)\n\n# density plot\nplot(density(gapminder_xlsx_2007$gdpPercap))\n\n# boxplot of population\nboxplot(gapminder_xlsx_2007$gdpPercap)\nboxplot.stats(gapminder_xlsx_2007$gdpPercap)\n#> $stats\n#> [1]   277.5519  1598.4351  6124.3711 18008.9444 40675.9964\n#> \n#> $n\n#> [1] 142\n#> \n#> $conf\n#> [1] 3948.491 8300.251\n#> \n#> $out\n#> [1] 47306.99 49357.19 47143.18 42951.65\nboxplot.stats(gapminder_xlsx_2007$gdpPercap)$stats\n#> [1]   277.5519  1598.4351  6124.3711 18008.9444 40675.9964\nsummary(gapminder_xlsx_2007$gdpPercap)\n#>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#>   277.6  1624.8  6124.4 11680.1 18008.8 49357.2\nboxplot.stats(gapminder_xlsx_2007$gdpPercap)$out\n#> [1] 47306.99 49357.19 47143.18 42951.65\n# changing coef\nboxplot.stats(gapminder_xlsx_2007$gdpPercap, coef = 0.8)$out\n#>  [1] 34435.37 36126.49 33692.61 36319.24 35278.42 33207.08\n#>  [7] 32170.37 39724.98 36180.79 40676.00 31656.07 47306.99\n#> [13] 36797.93 49357.19 47143.18 33859.75 37506.42 33203.26\n#> [19] 42951.65\nboxplot.stats(gapminder_xlsx_2007$gdpPercap, coef = 1)$out\n#>  [1] 34435.37 36126.49 36319.24 35278.42 39724.98 36180.79\n#>  [7] 40676.00 47306.99 36797.93 49357.19 47143.18 37506.42\n#> [13] 42951.65\nboxplot.stats(gapminder_xlsx_2007$gdpPercap, coef = 1.2)$out\n#> [1] 39724.98 40676.00 47306.99 49357.19 47143.18 42951.65\n\n# selecting outliers\ngapminder_xlsx_2007[gapminder_xlsx_2007$gdpPercap >= min(boxplot.stats(gapminder_xlsx_2007$gdpPercap)$out),]\n#>            country continent year lifeExp       pop\n#> 864         Kuwait      Asia 2007  77.588   2505559\n#> 1152        Norway    Europe 2007  80.196   4627926\n#> 1368     Singapore      Asia 2007  79.972   4553009\n#> 1620 United States  Americas 2007  78.242 301139947\n#>      gdpPercap      country_hun continent_hun\n#> 864   47306.99           Kuvait         Ázsia\n#> 1152  49357.19         Norvégia        Európa\n#> 1368  47143.18        Szingapúr         Ázsia\n#> 1620  42951.65 Egyesült Államok       Amerika"},{"path":"advanced-data-manipulation.html","id":"dealing-with-duplicate-values","chapter":"4 Advanced data manipulation","heading":"4.11 Dealing with duplicate values","text":"","code":""},{"path":"advanced-data-manipulation.html","id":"determining-duplicate-values","chapter":"4 Advanced data manipulation","heading":"4.11.1 Determining duplicate values","text":"function duplicated() determines elements duplicates vector data frame function anyDuplicated() returns index position first duplicate.function duplicated() anyDuplicated() also work data frames. former drops unique rows keeping duplicate rows.","code":"\n# checking for duplicates\nduplicated(1:10)\n#>  [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n#> [10] FALSE\n\nduplicated(c(2, 1, 3, 6, 2, 4, 7, 0, 3, 3, 2, 2, 8, 4, 0))\n#>  [1] FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE  TRUE\n#> [10]  TRUE  TRUE  TRUE FALSE  TRUE  TRUE\n\n# get duplicate values\nvt <- c(2, 1, 3, 6, 2, 4, 7, 0, 3, 3, 2, 2, 8, 4, 0)\nvt[duplicated(c(2, 1, 3, 6, 2, 4, 7, 0, 3, 3, 2, 2, 8, 4, 0))]\n#> [1] 2 3 3 2 2 4 0\n\n# checking if an object contains any duplicates\nany(duplicated(1:10))\n#> [1] FALSE\n\nany(duplicated(c(2, 1, 3, 6, 2, 4, 7, 0, 3, 3, 2, 2, 8, 4, 0)))\n#> [1] TRUE\n\n# get the first duplicate position\nanyDuplicated(1:10)\n#> [1] 0\n\nanyDuplicated(c(2, 1, 3, 6, 2, 4, 7, 0, 3, 3, 2, 2, 8, 4, 0))\n#> [1] 5\nmovies_2006 <- mov[mov$Year == 2006, c(7,12)]\nmovies_2006 <- movies_2006[order(movies_2006$Year, movies_2006$Metascore),]\nhead(movies_2006)\n#>     Year Metascore\n#> 774 2006        36\n#> 309 2006        45\n#> 551 2006        45\n#> 594 2006        45\n#> 734 2006        46\n#> 531 2006        47\n\n# checking for any duplicates\nany(duplicated(movies_2006))\n#> [1] TRUE\n\nanyDuplicated(movies_2006)\n#> [1] 3\n\n# checking for duplicates\nduplicated(movies_2006)\n#>  [1] FALSE FALSE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE\n#> [10]  TRUE FALSE  TRUE FALSE FALSE  TRUE FALSE FALSE FALSE\n#> [19]  TRUE  TRUE FALSE FALSE  TRUE  TRUE  TRUE FALSE  TRUE\n#> [28] FALSE  TRUE FALSE FALSE FALSE FALSE  TRUE FALSE  TRUE\n#> [37] FALSE FALSE  TRUE FALSE FALSE FALSE  TRUE  TRUE\n\n# returning duplicates\nmovies_2006_dup <- movies_2006 [duplicated(movies_2006), ]\nhead(movies_2006_dup)\n#>     Year Metascore\n#> 551 2006        45\n#> 594 2006        45\n#> 859 2006        52\n#> 960 2006        53\n#> 902 2006        58\n#> 670 2006        64"},{"path":"advanced-data-manipulation.html","id":"get-unique-values","chapter":"4 Advanced data manipulation","heading":"4.11.2 Get unique values","text":"function unique() extracts unique values vector data frame.","code":"\n# return unique values\nunique(1:10)\n#>  [1]  1  2  3  4  5  6  7  8  9 10\n\nunique(c(2, 1, 3, 6, 2, 4, 7, 0, 3, 3, 2, 2, 8, 4, 0))\n#> [1] 2 1 3 6 4 7 0 8\n\n# return unique values using duplicated()\nvt[!duplicated(c(2, 1, 3, 6, 2, 4, 7, 0, 3, 3, 2, 2, 8, 4, 0))]\n#> [1] 2 1 3 6 4 7 0 8\n\n# returning unique rows\nmovies_2006_uni <- unique(movies_2006)\nhead(movies_2006_uni)\n#>     Year Metascore\n#> 774 2006        36\n#> 309 2006        45\n#> 734 2006        46\n#> 531 2006        47\n#> 321 2006        48\n#> 775 2006        51\n\n# returning unique rows using duplicated()\nmovies_2006_uni <- subset(movies_2006, !duplicated(movies_2006))\nhead(movies_2006_uni)\n#>     Year Metascore\n#> 774 2006        36\n#> 309 2006        45\n#> 734 2006        46\n#> 531 2006        47\n#> 321 2006        48\n#> 775 2006        51"},{"path":"modern-graphics.html","id":"modern-graphics","chapter":"5 Modern graphics","heading":"5 Modern graphics","text":"","code":""},{"path":"tidyverse-r.html","id":"tidyverse-r","chapter":"6 Tidyverse R","heading":"6 Tidyverse R","text":"","code":""},{"path":"bioconductor.html","id":"bioconductor","chapter":"7 Bioconductor","heading":"7 Bioconductor","text":"","code":""},{"path":"rna-seq-an-example.html","id":"rna-seq-an-example","chapter":"8 RNA-Seq (an example)","heading":"8 RNA-Seq (an example)","text":"","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
